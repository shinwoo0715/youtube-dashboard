import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import numpy as np
from datetime import datetime, timedelta
import re
import io
import base64
from collections import Counter
import urllib.parse

from youtube_analyzer import YouTubeAnalyzer
from url_parser import YouTubeURLParser
from data_visualizer import DataVisualizer

# Page configuration
st.set_page_config(
    page_title="üìä Ïú†ÌäúÎ∏å Ï±ÑÎÑê ÏôÑÏ†Ñ Î∂ÑÏÑù",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Revolutionary UI/UX Design System
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap');
    
    :root {
        --primary: #FF0000;
        --primary-light: #FF6B6B;
        --primary-dark: #CC0000;
        --secondary: #4ECDC4;
        --accent: #FFD93D;
        --bg-primary: #FFFFFF;
        --bg-secondary: #F8FAFC;
        --bg-tertiary: #F1F5F9;
        --text-primary: #1E293B;
        --text-secondary: #64748B;
        --border: #E2E8F0;
        --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
        --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
        --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        --shadow-xl: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
        --shadow-2xl: 0 25px 50px -12px rgba(0, 0, 0, 0.25);
    }
    
    /* Global Styles */
    .main {
        font-family: 'Noto Sans KR', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }
    
    .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    
    /* Glassmorphism Header */
    .main-header {
        text-align: center;
        padding: 4rem 3rem;
        background: rgba(255, 255, 255, 0.1);
        backdrop-filter: blur(20px);
        border: 1px solid rgba(255, 255, 255, 0.2);
        border-radius: 30px;
        margin: 2rem 0 3rem 0;
        position: relative;
        overflow: hidden;
        box-shadow: var(--shadow-2xl);
    }
    
    .main-header::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
        animation: shimmer 3s infinite;
    }
    
    @keyframes shimmer {
        0% { left: -100%; }
        100% { left: 100%; }
    }
    
    .main-header h1 {
        font-size: 3.5rem;
        font-weight: 800;
        margin-bottom: 1rem;
        background: linear-gradient(135deg, #FF0000, #FF6B6B, #FFD93D);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        text-shadow: none;
        letter-spacing: -0.02em;
    }
    
    .main-header p {
        font-size: 1.25rem;
        color: rgba(255, 255, 255, 0.9);
        font-weight: 400;
        letter-spacing: 0.01em;
    }
    
    /* Sidebar Design */
    .sidebar .stSelectbox, .sidebar .stTextInput, .sidebar .stTextArea, .sidebar .stNumberInput {
        margin-bottom: 1rem;
    }
    
    .sidebar .stSelectbox > div > div {
        background: rgba(255, 255, 255, 0.95);
        border: 1px solid rgba(255, 255, 255, 0.3);
        border-radius: 12px;
        backdrop-filter: blur(10px);
    }
    
    .sidebar .stTextInput > div > div > input {
        background: rgba(255, 255, 255, 0.95);
        border: 1px solid rgba(255, 255, 255, 0.3);
        border-radius: 12px;
        backdrop-filter: blur(10px);
        padding: 12px 16px;
        font-weight: 500;
    }
    
    .sidebar .stButton > button {
        width: 100%;
        height: 3.5rem;
        border-radius: 16px;
        font-weight: 700;
        font-size: 1.1rem;
        background: linear-gradient(135deg, #FF0000 0%, #FF6B6B 100%);
        border: none;
        color: white;
        transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
        box-shadow: var(--shadow-lg);
        position: relative;
        overflow: hidden;
    }
    
    .sidebar .stButton > button::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
        transition: left 0.5s;
    }
    
    .sidebar .stButton > button:hover {
        transform: translateY(-3px);
        box-shadow: var(--shadow-xl);
    }
    
    .sidebar .stButton > button:hover::before {
        left: 100%;
    }
    
    /* Enhanced Tabs */
    .stTabs [data-baseweb="tab-list"] {
        gap: 12px;
        background: rgba(255, 255, 255, 0.1);
        padding: 8px;
        border-radius: 20px;
        backdrop-filter: blur(10px);
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 3.5rem;
        padding: 12px 24px;
        background: rgba(255, 255, 255, 0.1);
        border-radius: 16px;
        border: 1px solid rgba(255, 255, 255, 0.2);
        font-weight: 600;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        backdrop-filter: blur(10px);
        color: rgba(255, 255, 255, 0.8);
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #FF0000 0%, #FF6B6B 100%);
        color: white !important;
        box-shadow: var(--shadow-lg);
        border: 1px solid rgba(255, 255, 255, 0.3);
        transform: translateY(-2px);
    }
    
    /* Glassmorphism Cards */
    .metric-card, .element-container .stMetric {
        background: rgba(255, 255, 255, 0.15);
        backdrop-filter: blur(20px);
        padding: 2rem;
        border-radius: 20px;
        border: 1px solid rgba(255, 255, 255, 0.2);
        margin: 1rem 0;
        box-shadow: var(--shadow-lg);
        transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
        position: relative;
        overflow: hidden;
    }
    
    .metric-card::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 3px;
        background: linear-gradient(90deg, #FF0000, #FF6B6B, #FFD93D, #4ECDC4);
    }
    
    .metric-card:hover, .element-container .stMetric:hover {
        transform: translateY(-8px) scale(1.02);
        box-shadow: var(--shadow-2xl);
        background: rgba(255, 255, 255, 0.2);
    }
    
    /* Data Tables */
    .stDataFrame {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 20px;
        overflow: hidden;
        box-shadow: var(--shadow-lg);
        backdrop-filter: blur(20px);
    }
    
    .stDataFrame thead tr th {
        background: linear-gradient(135deg, #FF0000 0%, #FF6B6B 100%);
        color: white;
        font-weight: 700;
        padding: 16px;
        border: none;
    }
    
    .stDataFrame tbody tr:nth-child(even) {
        background: rgba(248, 250, 252, 0.5);
    }
    
    .stDataFrame tbody tr:hover {
        background: rgba(255, 107, 107, 0.1);
        transform: scale(1.01);
        transition: all 0.2s ease;
    }
    
    /* Progress and Status */
    .progress-container {
        background: rgba(255, 255, 255, 0.15);
        backdrop-filter: blur(20px);
        padding: 2rem;
        border-radius: 20px;
        margin: 2rem 0;
        border: 1px solid rgba(255, 255, 255, 0.2);
        box-shadow: var(--shadow-lg);
    }
    
    .error-message {
        background: rgba(255, 235, 238, 0.9);
        backdrop-filter: blur(10px);
        color: #c62828;
        padding: 2rem;
        border-radius: 20px;
        border-left: 5px solid #FF4444;
        margin: 2rem 0;
        box-shadow: var(--shadow-lg);
        animation: slideInUp 0.6s cubic-bezier(0.4, 0, 0.2, 1);
    }
    
    .success-message {
        background: rgba(232, 245, 232, 0.9);
        backdrop-filter: blur(10px);
        color: #2e7d32;
        padding: 2rem;
        border-radius: 20px;
        border-left: 5px solid #4CAF50;
        margin: 2rem 0;
        box-shadow: var(--shadow-lg);
        animation: slideInUp 0.6s cubic-bezier(0.4, 0, 0.2, 1);
    }
    
    @keyframes slideInUp {
        from {
            opacity: 0;
            transform: translateY(30px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    /* Enhanced Expanders */
    .streamlit-expanderHeader {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 16px;
        padding: 16px 20px;
        font-weight: 600;
        border: 1px solid rgba(255, 255, 255, 0.2);
        backdrop-filter: blur(10px);
    }
    
    .streamlit-expanderContent {
        background: rgba(255, 255, 255, 0.05);
        border-radius: 0 0 16px 16px;
        border: 1px solid rgba(255, 255, 255, 0.1);
        backdrop-filter: blur(10px);
    }
    
    /* Floating Action Elements */
    .floating-widget {
        position: fixed;
        bottom: 2rem;
        right: 2rem;
        background: linear-gradient(135deg, #FF0000 0%, #FF6B6B 100%);
        color: white;
        padding: 1rem;
        border-radius: 50%;
        box-shadow: var(--shadow-xl);
        cursor: pointer;
        transition: all 0.3s ease;
        z-index: 1000;
    }
    
    .floating-widget:hover {
        transform: scale(1.1) rotate(5deg);
        box-shadow: var(--shadow-2xl);
    }
    
    /* Plotly Chart Container */
    .plotly-graph-div {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 20px;
        padding: 1rem;
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.2);
        margin: 1rem 0;
    }
    
    /* Custom Scrollbar */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    
    ::-webkit-scrollbar-track {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 10px;
    }
    
    ::-webkit-scrollbar-thumb {
        background: linear-gradient(135deg, #FF0000, #FF6B6B);
        border-radius: 10px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: linear-gradient(135deg, #CC0000, #FF4444);
    }
    
    /* Mobile Optimizations */
    @media (max-width: 768px) {
        .main-header h1 {
            font-size: 2.5rem;
        }
        
        .main-header {
            padding: 3rem 2rem;
            margin: 1rem 0 2rem 0;
        }
        
        .metric-card {
            padding: 1.5rem;
        }
        
        .stTabs [data-baseweb="tab"] {
            padding: 10px 16px;
            font-size: 0.9rem;
        }
        
        .floating-widget {
            bottom: 1rem;
            right: 1rem;
        }
    }
    
    /* Loading Animations */
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }
    
    @keyframes bounce {
        0%, 20%, 53%, 80%, 100% { transform: translateY(0); }
        40%, 43% { transform: translateY(-10px); }
        70% { transform: translateY(-5px); }
        90% { transform: translateY(-2px); }
    }
    
    .loading {
        animation: pulse 2s infinite;
    }
    
    .bounce {
        animation: bounce 1s infinite;
    }
    
    /* Dark Mode Support */
    @media (prefers-color-scheme: dark) {
        :root {
            --bg-primary: #0F172A;
            --bg-secondary: #1E293B;
            --bg-tertiary: #334155;
            --text-primary: #F8FAFC;
            --text-secondary: #CBD5E1;
            --border: #475569;
        }
        
        .main {
            background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
        }
    }
</style>
""", unsafe_allow_html=True)

def initialize_session_state():
    """Initialize session state variables"""
    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = None
    if 'channel_data' not in st.session_state:
        st.session_state.channel_data = None
    if 'analysis_complete' not in st.session_state:
        st.session_state.analysis_complete = False
    if 'progress_messages' not in st.session_state:
        st.session_state.progress_messages = []
    if 'error_message' not in st.session_state:
        st.session_state.error_message = None

def show_progress(message):
    """Add progress message to session state"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.progress_messages.append(f"[{timestamp}] {message}")

def display_progress():
    """Display progress messages"""
    if st.session_state.progress_messages:
        st.markdown('<div class="progress-container">', unsafe_allow_html=True)
        st.subheader("üìà Î∂ÑÏÑù ÏßÑÌñâ ÏÉÅÌô©")
        for message in st.session_state.progress_messages[-10:]:  # Show last 10 messages
            st.text(message)
        st.markdown('</div>', unsafe_allow_html=True)

def display_error(error_msg):
    """Display error message with styling"""
    st.markdown(f'<div class="error-message">‚ùå <strong>Ïò§Î•ò:</strong> {error_msg}</div>', unsafe_allow_html=True)

def display_success(success_msg):
    """Display success message with styling"""
    st.markdown(f'<div class="success-message">‚úÖ <strong>ÏÑ±Í≥µ:</strong> {success_msg}</div>', unsafe_allow_html=True)

def main():
    initialize_session_state()
    st.title("Ïú†ÌäúÎ∏å Îç∞Ïù¥ÌÑ∞ ÎåÄÏãúÎ≥¥Îìú")
    st.write("Ïï±Ïù¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú Ïã§ÌñâÎêòÏóàÏäµÎãàÎã§.")

    # Main header with enhanced features
    st.markdown("""
    <div class="main-header">
        <h1>üìä Ïú†ÌäúÎ∏å Ï±ÑÎÑê ÏôÑÏ†Ñ Î∂ÑÏÑù</h1>
        <p>AI Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù ¬∑ Ïã§ÏãúÍ∞Ñ Ìä∏Î†åÎìú ÏòàÏ∏° ¬∑ ÏÑ±Í≥º ÏµúÏ†ÅÌôî</p>
        <div style="margin-top: 2rem; display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap;">
            <span style="background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 20px; font-size: 0.9rem;">‚ú® Ïã§ÏãúÍ∞Ñ Î∂ÑÏÑù</span>
            <span style="background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 20px; font-size: 0.9rem;">üéØ ÏÑ±Í≥µ Ìå®ÌÑ¥ AI</span>
            <span style="background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 20px; font-size: 0.9rem;">üìà Ìä∏Î†åÎìú ÏòàÏ∏°</span>
            <span style="background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 20px; font-size: 0.9rem;">üîÆ ÏàòÏùµ ÏòàÏÉÅ</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Add floating help button
    st.markdown("""
    <div class="floating-widget" title="ÎèÑÏõÄÎßê">
        <div style="font-size: 1.5rem;">‚ùì</div>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar for inputs
    with st.sidebar:
        st.header("üîß ÏÑ§Ï†ï")
        
        # API Key input
        st.subheader("üîë YouTube Data API ÌÇ§")
        api_key = st.text_input(
            "YouTube Data API ÌÇ§Î•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî",
            type="password",
            help="Google Cloud ConsoleÏóêÏÑú YouTube Data API v3 ÌÇ§Î•º Î∞úÍ∏âÎ∞õÏúºÏÑ∏Ïöî"
        )
        
        if not api_key:
            st.warning("‚ö†Ô∏è ÏßÑÌñâÌïòÎ†§Î©¥ YouTube Data API ÌÇ§Î•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî")
            st.markdown("""
            **API ÌÇ§ Î∞úÍ∏â Î∞©Î≤ï:**
            1. [Google Cloud Console](https://console.cloud.google.com/) Ï†ëÏÜç
            2. ÏÉà ÌîÑÎ°úÏ†ùÌä∏ ÏÉùÏÑ± ÎòêÎäî Í∏∞Ï°¥ ÌîÑÎ°úÏ†ùÌä∏ ÏÑ†ÌÉù
            3. YouTube Data API v3 ÌôúÏÑ±Ìôî
            4. ÏÇ¨Ïö©Ïûê Ïù∏Ï¶ù Ï†ïÎ≥¥ ÏÉùÏÑ± (API ÌÇ§)
            5. ÏúÑÏóê ÌÇ§Î•º Î≥µÏÇ¨Ìï¥ÏÑú Î∂ôÏó¨ÎÑ£Í∏∞
            """)
        
        # Channel input
        st.subheader("üì∫ Ï±ÑÎÑê Ï†ïÎ≥¥")
        channel_input = st.text_input(
            "Ï±ÑÎÑêÎ™Ö ÎòêÎäî URL",
            placeholder="Ïòà: ÏπôÏπôÌíâÌíâ ÎòêÎäî https://www.youtube.com/@ÏπôÏπôÌíâÌíâ",
            help="Ï±ÑÎÑêÎ™Ö, @Ìï∏Îì§, ÎòêÎäî Î™®Îì† ÌòïÌÉúÏùò Ïú†ÌäúÎ∏å Ï±ÑÎÑê URLÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî"
        )
        
        # Advanced Analysis options
        st.subheader("‚öôÔ∏è Í≥†Í∏â Î∂ÑÏÑù ÏòµÏÖò")
        
        # Basic options
        with st.expander("üìä Í∏∞Î≥∏ ÏÑ§Ï†ï", expanded=True):
            max_videos = st.selectbox(
                "Î∂ÑÏÑùÌï† ÏµúÎåÄ ÏòÅÏÉÅ Ïàò",
                [10, 20, 50, 100, 200, 500, 1000, 2000, 5000],
                index=4,
                help="Îçî ÎßéÏùÄ ÏòÅÏÉÅ = Îçî Ï†ïÌôïÌïú Î∂ÑÏÑù (Ï≤òÎ¶¨ ÏãúÍ∞Ñ Ï¶ùÍ∞Ä)"
            )
            
            col1, col2 = st.columns(2)
            with col1:
                include_shorts = st.checkbox("ÏáºÏ∏† Ìè¨Ìï®", value=True)
            with col2:
                include_long_form = st.checkbox("Î°±Ìèº Ìè¨Ìï®", value=True)
        
        # Date range filter
        with st.expander("üìÖ ÎÇ†Ïßú ÌïÑÌÑ∞"):
            use_date_filter = st.checkbox("ÎÇ†Ïßú Î≤îÏúÑ ÏÑ§Ï†ï")
            if use_date_filter:
                date_from = st.date_input("ÏãúÏûë ÎÇ†Ïßú", value=datetime.now() - timedelta(days=365))
                date_to = st.date_input("Ï¢ÖÎ£å ÎÇ†Ïßú", value=datetime.now())
        
        # Performance filters
        with st.expander("üéØ ÏÑ±Í≥º ÌïÑÌÑ∞"):
            min_views = st.number_input("ÏµúÏÜå Ï°∞ÌöåÏàò", min_value=0, value=0)
            min_likes = st.number_input("ÏµúÏÜå Ï¢ãÏïÑÏöî Ïàò", min_value=0, value=0)
            
        # Analysis depth
        with st.expander("üîç Î∂ÑÏÑù ÍπäÏù¥"):
            analyze_thumbnails = st.checkbox("Ïç∏ÎÑ§Ïùº ÏÉâÏÉÅ Î∂ÑÏÑù", value=True)
            analyze_sentiment = st.checkbox("Ï†úÎ™© Í∞êÏ†ï Î∂ÑÏÑù", value=True)
            predict_trends = st.checkbox("Ìä∏Î†åÎìú ÏòàÏ∏°", value=True)
            competitor_analysis = st.checkbox("Í≤ΩÏüÅÏûê Î∂ÑÏÑù (Î≤†ÌÉÄ)", value=False)
        
        # Export options
        with st.expander("üíæ ÎÇ¥Î≥¥ÎÇ¥Í∏∞ ÏÑ§Ï†ï"):
            export_format = st.selectbox("ÎÇ¥Î≥¥ÎÇ¥Í∏∞ ÌòïÏãù", ["Excel", "CSV", "JSON"])
            include_charts = st.checkbox("Ï∞®Ìä∏ Ïù¥ÎØ∏ÏßÄ Ìè¨Ìï®", value=True)
        
        st.divider()
        
        # Analysis button
        analyze_button = st.button(
            "üöÄ Î∂ÑÏÑù ÏãúÏûë",
            type="primary",
            disabled=not (api_key and channel_input),
            use_container_width=True
        )
    
    # Main content area
    if analyze_button and api_key and channel_input:
        st.session_state.progress_messages = []
        st.session_state.error_message = None
        st.session_state.analysis_complete = False
        
        # Initialize analyzer
        show_progress("Ïú†ÌäúÎ∏å Î∂ÑÏÑùÍ∏∞ Ï¥àÍ∏∞Ìôî Ï§ë...")
        st.session_state.analyzer = YouTubeAnalyzer(api_key)
        
        # Parse channel input
        show_progress("Ï±ÑÎÑê Ï†ïÎ≥¥ ÌååÏã± Ï§ë...")
        parser = YouTubeURLParser()
        
        try:
            channel_info = parser.parse_channel_input(channel_input)
            show_progress(f"Ï±ÑÎÑê ÌååÏã± ÏôÑÎ£å: {channel_info}")
            
            # Get channel data
            show_progress("Ï±ÑÎÑê ÏÑ∏Î∂Ä Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Îäî Ï§ë...")
            channel_data = st.session_state.analyzer.get_channel_info(channel_info)
            
            if not channel_data:
                display_error("Ï±ÑÎÑêÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. Ï±ÑÎÑêÎ™ÖÏù¥ÎÇò URLÏùÑ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.")
                return
            
            show_progress(f"Ï±ÑÎÑê Î∞úÍ≤¨: {channel_data.get('title', 'Ïïå Ïàò ÏóÜÏùå')}")
            
            # Create progress container
            progress_container = st.container()
            with progress_container:
                display_progress()
            
            # Collect video data
            show_progress("ÏòÅÏÉÅ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ï§ë... ÏãúÍ∞ÑÏù¥ ÏÜåÏöîÎê† Ïàò ÏûàÏäµÎãàÎã§.")
            
            # Create a progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def progress_callback(current, total, message):
                progress = min(current / total, 1.0) if total > 0 else 0
                progress_bar.progress(progress)
                status_text.text(f"{message} ({current}/{total})")
                show_progress(f"{message} ({current}/{total})")
            
            videos_data = st.session_state.analyzer.collect_all_videos(
                channel_data['id'],
                max_results=max_videos,
                include_shorts=include_shorts,
                include_long_form=include_long_form,
                progress_callback=progress_callback
            )
            
            if not videos_data:
                display_error("Ïù¥ Ï±ÑÎÑêÏóêÏÑú ÏòÅÏÉÅÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
                return
            
            progress_bar.progress(1.0)
            status_text.text(f"Î∂ÑÏÑù ÏôÑÎ£å! {len(videos_data)}Í∞ú ÏòÅÏÉÅÏùÑ Î∞úÍ≤¨ÌñàÏäµÎãàÎã§.")
            
            # Store data in session state
            st.session_state.channel_data = {
                'channel_info': channel_data,
                'videos': videos_data
            }
            st.session_state.analysis_complete = True
            
            display_success(f"{channel_data.get('title', 'Ïïå Ïàò ÏóÜÎäî')} Ï±ÑÎÑêÏùò {len(videos_data)}Í∞ú ÏòÅÏÉÅ Î∂ÑÏÑùÏùÑ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏôÑÎ£åÌñàÏäµÎãàÎã§!")
            
        except Exception as e:
            display_error(f"Î∂ÑÏÑù Ïã§Ìå®: {str(e)}")
            st.error(f"ÏÉÅÏÑ∏ Ïò§Î•ò: {str(e)}")
            return
    
    # Display results if analysis is complete
    if st.session_state.analysis_complete and st.session_state.channel_data:
        display_analysis_results()

def display_analysis_results():
    """Display comprehensive analysis results"""
    channel_info = st.session_state.channel_data['channel_info']
    videos_data = st.session_state.channel_data['videos']
    
    # Create visualizer
    visualizer = DataVisualizer(videos_data)
    
    st.header(f"üìä {channel_info.get('title', 'Ïïå Ïàò ÏóÜÎäî Ï±ÑÎÑê')} Î∂ÑÏÑù Í≤∞Í≥º")
    
    # Channel overview with enhanced metrics
    col1, col2, col3, col4 = st.columns(4)
    
    total_videos = len(videos_data)
    total_views = sum(video.get('view_count', 0) for video in videos_data)
    total_likes = sum(video.get('like_count', 0) for video in videos_data)
    total_comments = sum(video.get('comment_count', 0) for video in videos_data)
    avg_views = total_views / total_videos if total_videos > 0 else 0
    
    shorts_count = sum(1 for video in videos_data if video.get('is_short', False))
    long_form_count = total_videos - shorts_count
    
    # Calculate engagement metrics
    total_engagement = total_likes + total_comments
    avg_engagement_rate = (total_engagement / total_views * 100) if total_views > 0 else 0
    
    with col1:
        st.metric("Ï¥ù ÏòÅÏÉÅ Ïàò", f"{total_videos:,}")
        st.metric("ÏáºÏ∏†", f"{shorts_count:,}")
    
    with col2:
        st.metric("Ï¥ù Ï°∞ÌöåÏàò", f"{total_views:,}")
        st.metric("ÌèâÍ∑† Ï°∞ÌöåÏàò", f"{avg_views:,.0f}")
    
    with col3:
        st.metric("Ï¥ù Ï¢ãÏïÑÏöî", f"{total_likes:,}")
        st.metric("Î°±Ìèº", f"{long_form_count:,}")
    
    with col4:
        subscriber_count = channel_info.get('subscriber_count', 0)
        video_count = channel_info.get('video_count', 0)
        st.metric("Íµ¨ÎèÖÏûê Ïàò", f"{subscriber_count:,}")
        st.metric("Ï±ÑÎÑê Ï¥ù ÏòÅÏÉÅ", f"{video_count:,}")
    
    # Additional metrics row
    col5, col6, col7, col8 = st.columns(4)
    
    with col5:
        st.metric("Ï¥ù ÎåìÍ∏Ä", f"{total_comments:,}")
    
    with col6:
        st.metric("ÌèâÍ∑† Ï∞∏Ïó¨Ïú®", f"{avg_engagement_rate:.2f}%")
    
    with col7:
        # Calculate average upload frequency
        if total_videos > 1:
            date_range = (max(video['published_at'] for video in videos_data) - 
                         min(video['published_at'] for video in videos_data)).days
            upload_frequency = date_range / total_videos if date_range > 0 else 0
            st.metric("ÌèâÍ∑† ÏóÖÎ°úÎìú Í∞ÑÍ≤©", f"{upload_frequency:.1f}Ïùº")
        else:
            st.metric("ÌèâÍ∑† ÏóÖÎ°úÎìú Í∞ÑÍ≤©", "N/A")
    
    with col8:
        # Most successful video
        if videos_data:
            best_video = max(videos_data, key=lambda x: x.get('view_count', 0))
            st.metric("ÏµúÍ≥† Ï°∞ÌöåÏàò", f"{best_video.get('view_count', 0):,}")
    
    # Create enhanced analysis tabs with new features
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9, tab10 = st.tabs([
        "üìà ÏÑ±Í≥º Í∞úÏöî",
        "üìÖ ÏóÖÎ°úÎìú Ìå®ÌÑ¥", 
        "üî• Ïù∏Í∏∞ ÏòÅÏÉÅ",
        "üî§ ÌÇ§ÏõåÎìú Î∂ÑÏÑù",
        "üéØ ÏÑ±Í≥µ Ìå®ÌÑ¥",
        "üí∞ ÏàòÏùµ Î∂ÑÏÑù",
        "ü§ñ AI Ï∂îÏ≤ú",
        "üìä ÏÉÅÏÑ∏ Îç∞Ïù¥ÌÑ∞",
        "üîÆ Ìä∏Î†åÎìú ÏòàÏ∏°",
        "üìã ÎÇ¥Î≥¥ÎÇ¥Í∏∞ & Î¶¨Ìè¨Ìä∏"
    ])
    
    with tab1:
        display_performance_overview(visualizer)
    
    with tab2:
        display_upload_patterns(visualizer)
    
    with tab3:
        display_top_videos(visualizer)
    
    with tab4:
        display_keywords_analysis(visualizer)
    
    with tab5:
        display_success_patterns(visualizer)
    
    with tab6:
        display_revenue_analysis(visualizer, channel_info)
    
    with tab7:
        display_ai_recommendations(visualizer, channel_info)
    
    with tab8:
        display_detailed_data()
    
    with tab9:
        display_trend_prediction(visualizer)
    
    with tab10:
        display_export_options(visualizer)

def display_performance_overview(visualizer):
    """Display performance overview charts"""
    st.subheader("üìà ÏÑ±Í≥º Í∞úÏöî")
    
    # Views distribution
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Ï°∞ÌöåÏàò Î∂ÑÌè¨")
        fig = visualizer.create_views_distribution()
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("Ï∞∏Ïó¨Ïú® Î∂ÑÏÑù")
        fig = visualizer.create_engagement_chart()
        st.plotly_chart(fig, use_container_width=True)
    
    # Performance comparison: Shorts vs Long-form
    st.subheader("üìä ÏáºÏ∏† vs Î°±Ìèº ÏÑ±Í≥º ÎπÑÍµê")
    fig = visualizer.create_shorts_vs_longform_comparison()
    st.plotly_chart(fig, use_container_width=True)
    
    # Duration vs Views correlation
    st.subheader("‚è±Ô∏è ÏòÅÏÉÅ Í∏∏Ïù¥ÏôÄ Ï°∞ÌöåÏàò ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ")
    fig = visualizer.create_duration_views_correlation()
    st.plotly_chart(fig, use_container_width=True)

def display_upload_patterns(visualizer):
    """Display upload pattern analysis"""
    st.subheader("üìÖ ÏóÖÎ°úÎìú Ìå®ÌÑ¥ Î∂ÑÏÑù")
    
    # Monthly upload trends
    st.subheader("üìä ÏõîÎ≥Ñ ÏóÖÎ°úÎìú Ìä∏Î†åÎìú")
    fig = visualizer.create_monthly_trends()
    st.plotly_chart(fig, use_container_width=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìÖ ÏöîÏùºÎ≥Ñ ÏóÖÎ°úÎìú Ìå®ÌÑ¥")
        fig = visualizer.create_weekday_analysis()
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("üïê ÏãúÍ∞ÑÎåÄÎ≥Ñ ÏóÖÎ°úÎìú Ìå®ÌÑ¥")
        fig = visualizer.create_hourly_analysis()
        st.plotly_chart(fig, use_container_width=True)
    
    # Upload consistency analysis
    st.subheader("üìà ÏóÖÎ°úÎìú ÏùºÍ¥ÄÏÑ± Î∂ÑÏÑù")
    consistency_data = visualizer.analyze_upload_consistency()
    
    # Display consistency data in a more user-friendly format
    if 'error' not in consistency_data:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Ï¥ù ÏòÅÏÉÅ Ïàò", f"{consistency_data['total_videos']:,}")
            st.metric("ÌôúÎèô Í∏∞Í∞Ñ", f"{consistency_data['date_range']['days_active']}Ïùº")
        
        with col2:
            st.metric("ÌèâÍ∑† ÏóÖÎ°úÎìú Í∞ÑÍ≤©", f"{consistency_data['upload_frequency']['average_gap_days']:.1f}Ïùº")
            st.metric("Ï£ºÎãπ ÏóÖÎ°úÎìú Ïàò", f"{consistency_data['upload_patterns']['uploads_per_week']:.1f}Í∞ú")
        
        with col3:
            st.metric("Í∞ÄÏû• ÌôúÎ∞úÌïú ÏöîÏùº", consistency_data['upload_patterns']['most_active_day'])
            st.metric("Ï£ºÏöî ÏóÖÎ°úÎìú ÏãúÍ∞Ñ", f"{consistency_data['upload_patterns']['most_active_hour']}Ïãú")
    else:
        st.error("Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.")

def display_top_videos(visualizer):
    """Display top performing videos"""
    st.subheader("üî• Ïù∏Í∏∞ ÏòÅÏÉÅ Î∂ÑÏÑù")
    
    # Top videos by different metrics
    metric_type = st.selectbox(
        "ÏÉÅÏúÑ ÏòÅÏÉÅ Ï†ïÎ†¨ Í∏∞Ï§Ä ÏÑ†ÌÉù",
        ["view_count", "like_count", "comment_count", "engagement_rate"],
        format_func=lambda x: {
            "view_count": "üëÅÔ∏è Ï°∞ÌöåÏàò",
            "like_count": "üëç Ï¢ãÏïÑÏöî", 
            "comment_count": "üí¨ ÎåìÍ∏ÄÏàò",
            "engagement_rate": "üìä Ï∞∏Ïó¨Ïú®"
        }[x]
    )
    
    # Number of top videos to display
    top_count = st.slider("ÌëúÏãúÌï† ÏÉÅÏúÑ ÏòÅÏÉÅ Ïàò", min_value=5, max_value=50, value=20)
    
    top_videos = visualizer.get_top_videos(metric=metric_type, count=top_count)
    
    # Display top videos table
    if top_videos:
        df = pd.DataFrame(top_videos)
        
        # Format the dataframe for display
        display_df = df[['title', 'published_at', 'view_count', 'like_count', 'comment_count', 'duration_formatted', 'is_short']].copy()
        display_df.columns = ['Ï†úÎ™©', 'ÏóÖÎ°úÎìúÏùº', 'Ï°∞ÌöåÏàò', 'Ï¢ãÏïÑÏöî', 'ÎåìÍ∏ÄÏàò', 'Í∏∏Ïù¥', 'Ïú†Ìòï']
        display_df['Ïú†Ìòï'] = ['ÏáºÏ∏†' if x else 'Î°±Ìèº' for x in display_df['Ïú†Ìòï']]
        
        # Format numbers with commas
        for col in ['Ï°∞ÌöåÏàò', 'Ï¢ãÏïÑÏöî', 'ÎåìÍ∏ÄÏàò']:
            if col in display_df.columns:
                display_df[col] = [f"{x:,}" if isinstance(x, (int, float)) else x for x in display_df[col]]
        
        st.dataframe(
            display_df,
            use_container_width=True,
            hide_index=True
        )
        
        # Top video performance chart
        metric_name = {
            "view_count": "Ï°∞ÌöåÏàò",
            "like_count": "Ï¢ãÏïÑÏöî",
            "comment_count": "ÎåìÍ∏ÄÏàò",
            "engagement_rate": "Ï∞∏Ïó¨Ïú®"
        }[metric_type]
        
        st.subheader(f"üìä {metric_name} Í∏∞Ï§Ä ÏÉÅÏúÑ 10Í∞ú ÏòÅÏÉÅ")
        fig = visualizer.create_top_videos_chart(metric=metric_type, count=10)
        st.plotly_chart(fig, use_container_width=True)
        
        # Performance insights
        if len(top_videos) >= 3:
            st.subheader("üí° Ïù∏Í∏∞ ÏòÅÏÉÅ Ïù∏ÏÇ¨Ïù¥Ìä∏")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ÏÉÅÏúÑ 3Í∞ú ÏòÅÏÉÅ ÌèâÍ∑† ÏÑ±Í≥º:**")
                top_3 = top_videos[:3]
                avg_views = sum(v['view_count'] for v in top_3) / 3
                avg_likes = sum(v['like_count'] for v in top_3) / 3
                avg_comments = sum(v['comment_count'] for v in top_3) / 3
                
                st.metric("ÌèâÍ∑† Ï°∞ÌöåÏàò", f"{avg_views:,.0f}")
                st.metric("ÌèâÍ∑† Ï¢ãÏïÑÏöî", f"{avg_likes:,.0f}")
                st.metric("ÌèâÍ∑† ÎåìÍ∏Ä", f"{avg_comments:,.0f}")
            
            with col2:
                st.write("**Ïù∏Í∏∞ ÏòÅÏÉÅ Ïú†Ìòï Î∂ÑÌè¨:**")
                shorts_in_top = sum(1 for v in top_videos[:10] if v.get('is_short', False))
                longform_in_top = 10 - shorts_in_top
                
                st.metric("ÏÉÅÏúÑ 10Í∞ú Ï§ë ÏáºÏ∏†", f"{shorts_in_top}Í∞ú")
                st.metric("ÏÉÅÏúÑ 10Í∞ú Ï§ë Î°±Ìèº", f"{longform_in_top}Í∞ú")
    else:
        st.info("ÌëúÏãúÌï† ÏòÅÏÉÅ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")

def display_success_patterns(visualizer):
    """Display analysis of successful video patterns"""
    st.subheader("üéØ ÏÑ±Í≥µ Ìå®ÌÑ¥ Î∂ÑÏÑù")
    
    # Get successful patterns
    patterns = visualizer.analyze_successful_patterns()
    
    if patterns and 'top_keywords' in patterns:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üî• Í≥†ÏÑ±Í≥º ÌÇ§ÏõåÎìú")
            if patterns.get('top_keywords'):
                keywords_data = []
                for keyword, data in list(patterns['top_keywords'].items())[:10]:
                    keywords_data.append({
                        'ÌÇ§ÏõåÎìú': keyword,
                        'ÏòÅÏÉÅÏàò': data['count'],
                        'ÌèâÍ∑† Ï°∞ÌöåÏàò': f"{data['avg_views']:,.0f}"
                    })
                
                if keywords_data:
                    st.dataframe(pd.DataFrame(keywords_data), use_container_width=True, hide_index=True)
                else:
                    st.info("ÌÇ§ÏõåÎìú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
            else:
                st.info("Î∂ÑÏÑùÌï† ÌÇ§ÏõåÎìúÍ∞Ä ÏóÜÏäµÎãàÎã§.")
        
        with col2:
            st.subheader("üìà ÏµúÏ†Å ÏóÖÎ°úÎìú ÏãúÍ∞Ñ")
            if patterns.get('best_times'):
                times_data = []
                for time_info in patterns['best_times'][:5]:
                    # Handle both dict and other formats safely
                    if isinstance(time_info, dict):
                        hour = time_info.get('hour', 0)
                        count = time_info.get('count', 0)
                        avg_views = time_info.get('avg_views', 0)
                        times_data.append({
                            'ÏãúÍ∞ÑÎåÄ': f"{hour}Ïãú",
                            'ÏòÅÏÉÅÏàò': count,
                            'ÌèâÍ∑† Ï°∞ÌöåÏàò': f"{avg_views:,.0f}"
                        })
                
                if times_data:
                    st.dataframe(pd.DataFrame(times_data), use_container_width=True, hide_index=True)
                else:
                    st.info("ÏãúÍ∞ÑÎåÄ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
            else:
                st.info("ÏóÖÎ°úÎìú ÏãúÍ∞Ñ Ìå®ÌÑ¥ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
    
    # Best performing video length analysis
    st.subheader("‚è±Ô∏è ÏµúÏ†Å ÏòÅÏÉÅ Í∏∏Ïù¥ Î∂ÑÏÑù")
    videos_data = visualizer.videos_data
    if videos_data:
        # Group by duration ranges
        duration_ranges = []
        for video in videos_data:
            duration = video.get('duration_seconds', 0)
            if duration <= 60:
                range_name = "ÏáºÏ∏† (‚â§60Ï¥à)"
            elif duration <= 300:
                range_name = "Îã®Ìé∏ (1-5Î∂Ñ)"
            elif duration <= 600:
                range_name = "Ï§ëÌé∏ (5-10Î∂Ñ)"
            elif duration <= 1200:
                range_name = "Ïû•Ìé∏ (10-20Î∂Ñ)"
            else:
                range_name = "Ïû•ÏãúÍ∞Ñ (>20Î∂Ñ)"
            
            duration_ranges.append({
                'range': range_name,
                'views': video.get('view_count', 0),
                'likes': video.get('like_count', 0),
                'comments': video.get('comment_count', 0)
            })
        
        if duration_ranges:
            df_duration = pd.DataFrame(duration_ranges)
            duration_summary = df_duration.groupby('range').agg({
                'views': ['count', 'mean', 'median'],
                'likes': 'mean',
                'comments': 'mean'
            }).round(0)
            
            duration_summary.columns = ['ÏòÅÏÉÅÏàò', 'ÌèâÍ∑†Ï°∞ÌöåÏàò', 'Ï§ëÍ∞ÑÏ°∞ÌöåÏàò', 'ÌèâÍ∑†Ï¢ãÏïÑÏöî', 'ÌèâÍ∑†ÎåìÍ∏Ä']
            duration_summary = duration_summary.reset_index()
            duration_summary.columns = ['Í∏∏Ïù¥Î≤îÏúÑ', 'ÏòÅÏÉÅÏàò', 'ÌèâÍ∑†Ï°∞ÌöåÏàò', 'Ï§ëÍ∞ÑÏ°∞ÌöåÏàò', 'ÌèâÍ∑†Ï¢ãÏïÑÏöî', 'ÌèâÍ∑†ÎåìÍ∏Ä']
            
            # Format numbers
            for col in ['ÏòÅÏÉÅÏàò', 'ÌèâÍ∑†Ï°∞ÌöåÏàò', 'Ï§ëÍ∞ÑÏ°∞ÌöåÏàò', 'ÌèâÍ∑†Ï¢ãÏïÑÏöî', 'ÌèâÍ∑†ÎåìÍ∏Ä']:
                duration_summary[col] = duration_summary[col].apply(lambda x: f"{int(x):,}")
            
            st.dataframe(duration_summary, use_container_width=True, hide_index=True)
    
    # Title pattern analysis
    st.subheader("üìù Ï†úÎ™© Ìå®ÌÑ¥ Î∂ÑÏÑù")
    if videos_data:
        # Analyze title characteristics of top performing videos
        top_videos = sorted(videos_data, key=lambda x: x.get('view_count', 0), reverse=True)[:20]
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            avg_title_length = sum(len(v.get('title', '')) for v in top_videos) / len(top_videos)
            st.metric("ÏÉÅÏúÑ ÏòÅÏÉÅ ÌèâÍ∑† Ï†úÎ™© Í∏∏Ïù¥", f"{avg_title_length:.0f}Ïûê")
        
        with col2:
            question_titles = sum(1 for v in top_videos if '?' in v.get('title', ''))
            st.metric("Î¨ºÏùåÌëú Ìè¨Ìï® Ï†úÎ™©", f"{question_titles}Í∞ú")
        
        with col3:
            exclamation_titles = sum(1 for v in top_videos if '!' in v.get('title', ''))
            st.metric("ÎäêÎÇåÌëú Ìè¨Ìï® Ï†úÎ™©", f"{exclamation_titles}Í∞ú")

def display_trend_prediction(visualizer):
    """Display trend prediction and future insights"""
    st.subheader("üîÆ Ìä∏Î†åÎìú ÏòàÏ∏° Î∞è Ïù∏ÏÇ¨Ïù¥Ìä∏")
    
    videos_data = visualizer.videos_data
    if not videos_data or len(videos_data) < 10:
        st.warning("Ìä∏Î†åÎìú ÏòàÏ∏°ÏùÑ ÏúÑÌï¥ÏÑúÎäî ÏµúÏÜå 10Í∞ú Ïù¥ÏÉÅÏùò ÏòÅÏÉÅÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.")
        return
    
    # Growth trend analysis
    st.subheader("üìà ÏÑ±Ïû• Ìä∏Î†åÎìú Î∂ÑÏÑù")
    
    # Sort videos by date
    sorted_videos = sorted(videos_data, key=lambda x: x.get('published_at'))
    
    # Calculate monthly growth
    monthly_data = {}
    for video in sorted_videos:
        month_key = video['published_at'].strftime('%Y-%m')
        if month_key not in monthly_data:
            monthly_data[month_key] = {
                'count': 0,
                'total_views': 0,
                'total_likes': 0,
                'total_comments': 0
            }
        monthly_data[month_key]['count'] += 1
        monthly_data[month_key]['total_views'] += video.get('view_count', 0)
        monthly_data[month_key]['total_likes'] += video.get('like_count', 0)
        monthly_data[month_key]['total_comments'] += video.get('comment_count', 0)
    
    if len(monthly_data) >= 3:
        months = sorted(monthly_data.keys())
        recent_months = months[-3:]
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            recent_avg_views = sum(monthly_data[m]['total_views'] for m in recent_months) / len(recent_months)
            older_months = months[:-3] if len(months) > 3 else months[:3]
            older_avg_views = sum(monthly_data[m]['total_views'] for m in older_months) / len(older_months) if older_months else recent_avg_views
            
            growth_rate = ((recent_avg_views - older_avg_views) / older_avg_views * 100) if older_avg_views > 0 else 0
            st.metric("ÏµúÍ∑º 3Í∞úÏõî ÏÑ±Ïû•Î•†", f"{growth_rate:+.1f}%")
        
        with col2:
            recent_upload_count = sum(monthly_data[m]['count'] for m in recent_months)
            st.metric("ÏµúÍ∑º 3Í∞úÏõî ÏóÖÎ°úÎìú", f"{recent_upload_count}Í∞ú")
        
        with col3:
            if len(recent_months) >= 2:
                last_month_views = monthly_data[recent_months[-1]]['total_views']
                prev_month_views = monthly_data[recent_months[-2]]['total_views']
                month_growth = ((last_month_views - prev_month_views) / prev_month_views * 100) if prev_month_views > 0 else 0
                st.metric("Ï†ÑÏõî ÎåÄÎπÑ ÏÑ±Ïû•Î•†", f"{month_growth:+.1f}%")
    
    # Content recommendations
    st.subheader("üí° ÏΩòÌÖêÏ∏† Ï∂îÏ≤ú")
    
    # Analyze successful content patterns
    top_performing = sorted(videos_data, key=lambda x: x.get('view_count', 0), reverse=True)[:10]
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ÏÑ±Í≥µ ÏöîÏù∏ Î∂ÑÏÑù:**")
        
        # Most successful video type
        shorts_performance = [v for v in top_performing if v.get('is_short', False)]
        longform_performance = [v for v in top_performing if not v.get('is_short', False)]
        
        if len(shorts_performance) > len(longform_performance):
            st.info("üéØ ÏáºÏ∏† ÏΩòÌÖêÏ∏†Í∞Ä Îçî ÎÜíÏùÄ ÏÑ±Í≥ºÎ•º Î≥¥ÏûÖÎãàÎã§")
        else:
            st.info("üéØ Î°±Ìèº ÏΩòÌÖêÏ∏†Í∞Ä Îçî ÎÜíÏùÄ ÏÑ±Í≥ºÎ•º Î≥¥ÏûÖÎãàÎã§")
        
        # Best upload day
        day_performance = {}
        for video in top_performing:
            day = video['published_at'].strftime('%A')
            if day not in day_performance:
                day_performance[day] = 0
            day_performance[day] += 1
        
        if day_performance:
            best_day = max(day_performance.keys(), key=lambda x: day_performance[x])
            day_names = {
                'Monday': 'ÏõîÏöîÏùº', 'Tuesday': 'ÌôîÏöîÏùº', 'Wednesday': 'ÏàòÏöîÏùº',
                'Thursday': 'Î™©ÏöîÏùº', 'Friday': 'Í∏àÏöîÏùº', 'Saturday': 'ÌÜ†ÏöîÏùº', 'Sunday': 'ÏùºÏöîÏùº'
            }
            st.info(f"üìÖ {day_names.get(best_day, best_day)}Ïóê ÏóÖÎ°úÎìúÌïú ÏòÅÏÉÅÏùò ÏÑ±Í≥ºÍ∞Ä Ï¢ãÏäµÎãàÎã§")
    
    with col2:
        st.write("**Í∞úÏÑ† Ï†úÏïà:**")
        
        # Upload consistency
        upload_gaps = []
        for i in range(1, len(sorted_videos)):
            gap = (sorted_videos[i]['published_at'] - sorted_videos[i-1]['published_at']).days
            upload_gaps.append(gap)
        
        if upload_gaps:
            avg_gap = sum(upload_gaps) / len(upload_gaps)
            if avg_gap > 7:
                st.warning("‚ö° ÏóÖÎ°úÎìú Ï£ºÍ∏∞Î•º Îçî ÏßßÍ≤å ÌïòÎ©¥ ÏÑ±Ïû•Ïóê ÎèÑÏõÄÏù¥ Îê† Ïàò ÏûàÏäµÎãàÎã§")
            elif avg_gap < 1:
                st.warning("‚è∞ ÎÑàÎ¨¥ ÏûêÏ£º ÏóÖÎ°úÎìúÌïòÎ©¥ ÌíàÏßàÏù¥ Îñ®Ïñ¥Ïßà Ïàò ÏûàÏäµÎãàÎã§")
            else:
                st.success("‚úÖ Ï†ÅÏ†àÌïú ÏóÖÎ°úÎìú Ï£ºÍ∏∞Î•º Ïú†ÏßÄÌïòÍ≥† ÏûàÏäµÎãàÎã§")
        
        # Engagement rate analysis
        recent_videos = sorted_videos[-10:] if len(sorted_videos) >= 10 else sorted_videos
        avg_engagement = sum(v.get('engagement_rate', 0) for v in recent_videos) / len(recent_videos)
        
        if avg_engagement < 2:
            st.warning("üí¨ ÏãúÏ≤≠Ïûê Ï∞∏Ïó¨ÎèÑÍ∞Ä ÎÇÆÏäµÎãàÎã§. ÎåìÍ∏ÄÏùÑ Ïú†ÎèÑÌïòÎäî ÏßàÎ¨∏Ïù¥ÎÇò ÏÉÅÌò∏ÏûëÏö©ÏùÑ ÎäòÎ†§Î≥¥ÏÑ∏Ïöî")
        elif avg_engagement > 5:
            st.success("üî• ÎÜíÏùÄ Ï∞∏Ïó¨ÎèÑÎ•º Ïú†ÏßÄÌïòÍ≥† ÏûàÏäµÎãàÎã§!")
        else:
            st.info("üìä ÌèâÍ∑†Ï†ÅÏù∏ Ï∞∏Ïó¨ÎèÑÏûÖÎãàÎã§. Îçî ÎßéÏùÄ ÏÉÅÌò∏ÏûëÏö©ÏùÑ ÏãúÎèÑÌï¥Î≥¥ÏÑ∏Ïöî")

def display_revenue_analysis(visualizer, channel_info):
    """Display revenue estimation and monetization analysis"""
    st.subheader("üí∞ ÏàòÏùµ Î∂ÑÏÑù Î∞è ÏòàÏÉÅ")
    
    videos_data = visualizer.videos_data
    if not videos_data:
        st.warning("ÏàòÏùµ Î∂ÑÏÑùÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
        return
    
    # Calculate revenue estimates
    total_views = sum(video.get('view_count', 0) for video in videos_data)
    subscriber_count = channel_info.get('subscriber_count', 0)
    
    # Revenue calculation (rough estimates based on industry averages)
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # Ad revenue estimation (RPM: Revenue per Mille)
        estimated_rpm = 1.5  # $1-3 per 1000 views average
        ad_revenue = (total_views / 1000) * estimated_rpm
        st.metric("ÏòàÏÉÅ Í¥ëÍ≥† ÏàòÏùµ", f"${ad_revenue:,.0f}")
    
    with col2:
        # Sponsorship potential
        if subscriber_count > 10000:
            sponsor_rate = subscriber_count * 0.01  # $0.01 per subscriber
            st.metric("Ïä§Ìè∞ÏÑúÏã≠ Ïû†Ïû¨Í∞ÄÏπò", f"${sponsor_rate:,.0f}")
        else:
            st.metric("Ïä§Ìè∞ÏÑúÏã≠ Ïû†Ïû¨Í∞ÄÏπò", "N/A")
    
    with col3:
        # Monthly earning potential
        from datetime import timezone
        now = datetime.now(timezone.utc)
        recent_videos = []
        for v in videos_data:
            pub_date = v['published_at']
            if hasattr(pub_date, 'tz_localize'):
                pub_date = pub_date.tz_localize('UTC') if pub_date.tz is None else pub_date
            elif not hasattr(pub_date, 'tzinfo') or pub_date.tzinfo is None:
                pub_date = pub_date.replace(tzinfo=timezone.utc)
            
            if (now - pub_date).days <= 30:
                recent_videos.append(v)
        monthly_views = sum(v.get('view_count', 0) for v in recent_videos)
        monthly_revenue = (monthly_views / 1000) * estimated_rpm
        st.metric("Ïõî ÏòàÏÉÅ ÏàòÏùµ", f"${monthly_revenue:,.0f}")
    
    with col4:
        # Growth potential
        if len(videos_data) >= 10:
            recent_avg = sum(v.get('view_count', 0) for v in videos_data[-5:]) / 5
            older_avg = sum(v.get('view_count', 0) for v in videos_data[-10:-5]) / 5
            growth = ((recent_avg - older_avg) / older_avg * 100) if older_avg > 0 else 0
            st.metric("ÏÑ±Ïû•Î•†", f"{growth:+.1f}%")
    
    # Revenue breakdown chart
    st.subheader("üìä ÏàòÏùµÏõêÎ≥Ñ Î∂ÑÏÑù")
    
    # Create revenue sources data
    revenue_sources = {
        'Í¥ëÍ≥† ÏàòÏùµ': ad_revenue,
        'Î©§Î≤ÑÏã≠': ad_revenue * 0.3,  # Estimated membership revenue
        'ÏäàÌçºÏ±ó': ad_revenue * 0.1,   # Estimated super chat
        'Î®∏Ï≤úÎã§Ïù¥Ï¶à': ad_revenue * 0.2  # Estimated merchandise
    }
    
    import plotly.express as px
    
    fig = px.pie(
        values=list(revenue_sources.values()),
        names=list(revenue_sources.keys()),
        title="ÏòàÏÉÅ ÏàòÏùµÏõê Î∂ÑÌè¨",
        color_discrete_sequence=['#FF0000', '#FF6B6B', '#FFD93D', '#4ECDC4']
    )
    
    fig.update_layout(
        font=dict(family="Noto Sans KR, sans-serif"),
        title_font=dict(size=16, family="Noto Sans KR, sans-serif")
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Revenue optimization tips
    st.subheader("üí° ÏàòÏùµ ÏµúÏ†ÅÌôî ÌåÅ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Ï¶âÏãú Ï†ÅÏö© Í∞ÄÎä•:**")
        tips = []
        
        if subscriber_count < 1000:
            tips.append("‚Ä¢ 1,000Î™Ö Íµ¨ÎèÖÏûê Îã¨ÏÑ±ÏúºÎ°ú ÏàòÏùµÌôî ÏãúÏûë")
        if len([v for v in videos_data if v.get('duration_seconds', 0) > 480]) < 5:
            tips.append("‚Ä¢ 8Î∂Ñ Ïù¥ÏÉÅ ÏòÅÏÉÅÏúºÎ°ú Ï§ëÍ∞Ñ Í¥ëÍ≥† ÏÇΩÏûÖ")
        if monthly_views < 10000:
            tips.append("‚Ä¢ ÏóÖÎ°úÎìú Ï£ºÍ∏∞ Îã®Ï∂ïÏúºÎ°ú ÎÖ∏Ï∂ú Ï¶ùÎåÄ")
        
        if not tips:
            tips = ["‚Ä¢ ÌòÑÏû¨ ÏàòÏùµÌôî Ï°∞Í±¥ÏùÑ Ïûò ÎßåÏ°±ÌïòÍ≥† ÏûàÏäµÎãàÎã§!"]
        
        for tip in tips:
            st.write(tip)
    
    with col2:
        st.write("**Ïû•Í∏∞ Ï†ÑÎûµ:**")
        long_term_tips = [
            "‚Ä¢ Î∏åÎûúÎìú ÌòëÏ∞¨ Î∞è Ï†úÌíà Î¶¨Î∑∞ ÏΩòÌÖêÏ∏†",
            "‚Ä¢ Ïò®ÎùºÏù∏ Í∞ïÏùò ÎòêÎäî ÏΩîÏπ≠ ÏÑúÎπÑÏä§",
            "‚Ä¢ Íµ¨ÎèÖÏûê Ï†ÑÏö© Î©§Î≤ÑÏã≠ ÌòúÌÉù",
            "‚Ä¢ Í¥ÄÎ†® ÏÉÅÌíà ÌåêÎß§ (Î®∏Ï≤úÎã§Ïù¥Ï¶à)"
        ]
        
        for tip in long_term_tips:
            st.write(tip)

def display_ai_recommendations(visualizer, channel_info):
    """Display AI-powered content recommendations"""
    st.subheader("ü§ñ AI Í∏∞Î∞ò ÏΩòÌÖêÏ∏† Ï∂îÏ≤ú")
    
    videos_data = visualizer.videos_data
    if not videos_data:
        st.warning("AI Ï∂îÏ≤úÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
        return
    
    # Analyze successful patterns
    top_videos = sorted(videos_data, key=lambda x: x.get('view_count', 0), reverse=True)[:10]
    
    # AI-style recommendations based on data analysis
    st.subheader("üéØ ÎßûÏ∂§Ìòï ÏΩòÌÖêÏ∏† Ï†ÑÎûµ")
    
    # Content type recommendation
    shorts_performance = [v for v in top_videos if v.get('is_short', False)]
    longform_performance = [v for v in top_videos if not v.get('is_short', False)]
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üì± ÏµúÏ†Å ÏΩòÌÖêÏ∏† ÌòïÏãù")
        if len(shorts_performance) > len(longform_performance):
            st.success("üéØ **ÏáºÏ∏† ÏΩòÌÖêÏ∏† ÏßëÏ§ë Ï∂îÏ≤ú**")
            st.write("‚Ä¢ 60Ï¥à Ïù¥Ìïò ÏûÑÌå©Ìä∏ ÏûàÎäî ÏΩòÌÖêÏ∏†")
            st.write("‚Ä¢ Ìä∏Î†åÎî© ÏùåÏïÖÍ≥º Ìï¥ÏãúÌÉúÍ∑∏ ÌôúÏö©")
            st.write("‚Ä¢ Îπ†Î•∏ Ìé∏ÏßëÍ≥º ÏãúÍ∞ÅÏ†Å Ìö®Í≥º")
        else:
            st.success("üéØ **Î°±Ìèº ÏΩòÌÖêÏ∏† ÏßëÏ§ë Ï∂îÏ≤ú**")
            st.write("‚Ä¢ 10-15Î∂Ñ Ïã¨Ï∏µ Î∂ÑÏÑù ÏΩòÌÖêÏ∏†")
            st.write("‚Ä¢ ÏÉÅÏÑ∏Ìïú Ï†ïÎ≥¥ÏôÄ Ïä§ÌÜ†Î¶¨ÌÖîÎßÅ")
            st.write("‚Ä¢ ÏãúÎ¶¨Ï¶àÎ¨ºÎ°ú Íµ¨ÎèÖÏûê Ïú†ÏßÄ")
    
    with col2:
        st.markdown("### ‚è∞ ÏµúÏ†Å ÏóÖÎ°úÎìú ÏãúÍ∞Ñ")
        
        # Find best upload times
        hour_performance = {}
        day_performance = {}
        
        for video in top_videos:
            hour = video['published_at'].hour
            day = video['published_at'].strftime('%A')
            
            if hour not in hour_performance:
                hour_performance[hour] = []
            if day not in day_performance:
                day_performance[day] = []
                
            hour_performance[hour].append(video.get('view_count', 0))
            day_performance[day].append(video.get('view_count', 0))
        
        # Calculate average performance
        best_hour = max(hour_performance.keys(), 
                       key=lambda x: sum(hour_performance[x]) / len(hour_performance[x])) if hour_performance else 12
        best_day = max(day_performance.keys(), 
                      key=lambda x: sum(day_performance[x]) / len(day_performance[x])) if day_performance else "Sunday"
        
        day_names = {
            'Monday': 'ÏõîÏöîÏùº', 'Tuesday': 'ÌôîÏöîÏùº', 'Wednesday': 'ÏàòÏöîÏùº',
            'Thursday': 'Î™©ÏöîÏùº', 'Friday': 'Í∏àÏöîÏùº', 'Saturday': 'ÌÜ†ÏöîÏùº', 'Sunday': 'ÏùºÏöîÏùº'
        }
        
        st.info(f"üïê **{best_hour}Ïãú ÏóÖÎ°úÎìú Ï∂îÏ≤ú**")
        st.info(f"üìÖ **{day_names.get(best_day, best_day)} ÏóÖÎ°úÎìú Ï∂îÏ≤ú**")
    
    # Title optimization
    st.subheader("üìù Ï†úÎ™© ÏµúÏ†ÅÌôî AI")
    
    # Analyze successful title patterns
    successful_titles = [v['title'] for v in top_videos if v.get('title')]
    
    if successful_titles:
        # Common words analysis
        from collections import Counter
        import re
        
        all_words = []
        for title in successful_titles:
            words = re.findall(r'\b\w+\b', title.lower())
            all_words.extend(words)
        
        common_words = Counter(all_words).most_common(10)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ÏÑ±Í≥µ ÌÇ§ÏõåÎìú TOP 5:**")
            for word, count in common_words[:5]:
                st.write(f"‚Ä¢ {word} ({count}Ìöå)")
        
        with col2:
            st.write("**Ï†úÎ™© Ìå®ÌÑ¥ Î∂ÑÏÑù:**")
            avg_length = sum(len(title) for title in successful_titles) / len(successful_titles)
            question_count = sum(1 for title in successful_titles if '?' in title)
            exclamation_count = sum(1 for title in successful_titles if '!' in title)
            
            st.write(f"‚Ä¢ ÏµúÏ†Å Ï†úÎ™© Í∏∏Ïù¥: {avg_length:.0f}Ïûê")
            st.write(f"‚Ä¢ Î¨ºÏùåÌëú ÏÇ¨Ïö©: {question_count}Í∞ú ÏòÅÏÉÅ")
            st.write(f"‚Ä¢ ÎäêÎÇåÌëú ÏÇ¨Ïö©: {exclamation_count}Í∞ú ÏòÅÏÉÅ")
    
    # Content gap analysis
    st.subheader("üîç ÏΩòÌÖêÏ∏† Í∞≠ Î∂ÑÏÑù")
    
    # Analyze upload frequency
    if len(videos_data) >= 5:
        recent_uploads = sorted(videos_data, key=lambda x: x['published_at'], reverse=True)[:5]
        upload_gaps = []
        
        for i in range(1, len(recent_uploads)):
            gap = (recent_uploads[i-1]['published_at'] - recent_uploads[i]['published_at']).days
            upload_gaps.append(gap)
        
        avg_gap = sum(upload_gaps) / len(upload_gaps) if upload_gaps else 7
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if avg_gap > 14:
                st.warning("‚ö†Ô∏è ÏóÖÎ°úÎìú Ï£ºÍ∏∞Í∞Ä ÎÑàÎ¨¥ ÍπÅÎãàÎã§")
                st.write("Í∂åÏû•: Ï£º 1-2Ìöå ÏóÖÎ°úÎìú")
            elif avg_gap < 2:
                st.warning("‚ö†Ô∏è ÎÑàÎ¨¥ ÏûêÏ£º ÏóÖÎ°úÎìúÌïòÍ≥† ÏûàÏäµÎãàÎã§")
                st.write("Í∂åÏû•: ÌíàÏßà Í¥ÄÎ¶¨Ïóê ÏßëÏ§ë")
            else:
                st.success("‚úÖ Ï†ÅÏ†àÌïú ÏóÖÎ°úÎìú Ï£ºÍ∏∞")
        
        with col2:
            # Suggest trending topics (mock data for demo)
            st.write("**Ìä∏Î†åÎî© ÌÜ†ÌîΩ Ï∂îÏ≤ú:**")
            trending_topics = ["AI ÌôúÏö©Î≤ï", "2025 Ìä∏Î†åÎìú", "Ìö®Ïú®Ï†ÅÏù∏ ÏûëÏóÖ", "ÏÉàÎ°úÏö¥ Í∏∞Ïà†", "ÎùºÏù¥ÌîÑÏä§ÌÉÄÏùº"]
            for topic in trending_topics[:3]:
                st.write(f"‚Ä¢ {topic}")
        
        with col3:
            st.write("**Í≤ΩÏüÅÏûê Î∂ÑÏÑù ÌïÑÏöî:**")
            st.write("‚Ä¢ Ïú†ÏÇ¨ Ï±ÑÎÑê Î≤§ÏπòÎßàÌÇπ")
            st.write("‚Ä¢ Ï∞®Î≥ÑÌôî Ìè¨Ïù∏Ìä∏ Î∞úÍµ¥")
            st.write("‚Ä¢ ÌòëÏóÖ Í∏∞Ìöå ÌÉêÏÉâ")
    
    # Action plan
    st.subheader("üìã Ïã§Ìñâ Í≥ÑÌöç")
    
    st.markdown("""
    ### üéØ Îã§Ïùå 30Ïùº Ïï°ÏÖò ÌîåÎûú
    
    **1Ï£ºÏ∞®**: ÏΩòÌÖêÏ∏† Í∏∞Ìöç Î∞è Ï†úÏûë
    - [ ] ÏÑ±Í≥µ ÌÇ§ÏõåÎìú Í∏∞Î∞ò ÏÉà ÏΩòÌÖêÏ∏† Í∏∞Ìöç
    - [ ] ÏµúÏ†Å ÏãúÍ∞ÑÎåÄ ÏóÖÎ°úÎìú Ïä§ÏºÄÏ§Ñ ÏÑ§Ï†ï
    - [ ] Ïç∏ÎÑ§Ïùº A/B ÌÖåÏä§Ìä∏ Ï§ÄÎπÑ
    
    **2Ï£ºÏ∞®**: ÏµúÏ†ÅÌôî Î∞è Î∂ÑÏÑù
    - [ ] Ï†úÎ™© Ìå®ÌÑ¥ Ï†ÅÏö© Î∞è ÌÖåÏä§Ìä∏
    - [ ] ÏãúÏ≤≠Ïûê Ï∞∏Ïó¨ÎèÑ Î™®ÎãàÌÑ∞ÎßÅ
    - [ ] ÎåìÍ∏Ä Î∞è Ïª§ÎÆ§ÎãàÌã∞ Í¥ÄÎ¶¨ Í∞ïÌôî
    
    **3Ï£ºÏ∞®**: ÌôïÏû• Î∞è Ïã§Ìóò
    - [ ] ÏÉàÎ°úÏö¥ ÏΩòÌÖêÏ∏† ÌòïÏãù Ïã§Ìóò
    - [ ] ÌòëÏóÖ ÎòêÎäî Í≤åÏä§Ìä∏ Ï∂úÏó∞ Í≤ÄÌÜ†
    - [ ] ÏãúÎ¶¨Ï¶à ÏΩòÌÖêÏ∏† Í∏∞Ìöç
    
    **4Ï£ºÏ∞®**: Î∂ÑÏÑù Î∞è Í∞úÏÑ†
    - [ ] ÏõîÍ∞Ñ ÏÑ±Í≥º Î∂ÑÏÑù
    - [ ] Îã§Ïùå Îã¨ Ï†ÑÎûµ ÏàòÏ†ï
    - [ ] ÏàòÏùµÌôî Î∞©Ïïà Í≤ÄÌÜ†
    """)
    
    # Interactive recommendations
    st.subheader("üîÆ Í∞úÏù∏ÌôîÎêú Ï∂îÏ≤ú")
    
    recommendation_type = st.selectbox(
        "Ïñ¥Îñ§ Î∂ÑÏïºÏùò Ï∂îÏ≤úÏùÑ Î∞õÍ≥† Ïã∂ÏúºÏã†Í∞ÄÏöî?",
        ["ÏΩòÌÖêÏ∏† Ï£ºÏ†ú", "Ìé∏Ïßë Ïä§ÌÉÄÏùº", "ÎßàÏºÄÌåÖ Ï†ÑÎûµ", "ÏàòÏùµÌôî Î∞©Î≤ï"]
    )
    
    if recommendation_type == "ÏΩòÌÖêÏ∏† Ï£ºÏ†ú":
        st.success("üé¨ Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞ò Ï∂îÏ≤ú Ï£ºÏ†ú:")
        st.write("‚Ä¢ ÏãúÏ≤≠ÏûêÎì§Ïù¥ Í∞ÄÏû• Ï¢ãÏïÑÌïòÎäî Ïä§ÌÉÄÏùºÏùò Ïã¨Ìôî Î≤ÑÏ†Ñ")
        st.write("‚Ä¢ ÌòÑÏû¨ Ìä∏Î†åÎî© Ï§ëÏù∏ ÌÇ§ÏõåÎìúÏôÄ Ï±ÑÎÑê ÌäπÏÑ± Í≤∞Ìï©")
        st.write("‚Ä¢ Í≥ÑÏ†àÏÑ±ÏùÑ Í≥†Î†§Ìïú ÌÉÄÏù¥Î∞ç ÏΩòÌÖêÏ∏†")
    
    elif recommendation_type == "Ìé∏Ïßë Ïä§ÌÉÄÏùº":
        st.success("‚úÇÔ∏è Ìé∏Ïßë Ïä§ÌÉÄÏùº Í∞úÏÑ†Ï†ê:")
        # Get performance data for editing recommendations
        top_videos = sorted(videos_data, key=lambda x: x.get('view_count', 0), reverse=True)[:10]
        shorts_performance = [v for v in top_videos if v.get('is_short', False)]
        longform_performance = [v for v in top_videos if not v.get('is_short', False)]
        
        if len(shorts_performance) > len(longform_performance):
            st.write("‚Ä¢ Îπ†Î•∏ Ïª∑ Ìé∏ÏßëÍ≥º Ïó≠ÎèôÏ†ÅÏù∏ Ìä∏ÎûúÏßÄÏÖò")
            st.write("‚Ä¢ ÏãúÍ∞ÅÏ†Å ÏûÑÌå©Ìä∏Î•º ÏúÑÌïú ÌÖçÏä§Ìä∏ Ïò§Î≤ÑÎ†àÏù¥")
        else:
            st.write("‚Ä¢ Ïä§ÌÜ†Î¶¨ÌÖîÎßÅÏùÑ ÏúÑÌïú ÏûêÏó∞Ïä§Îü¨Ïö¥ Ìé∏Ïßë")
            st.write("‚Ä¢ Ï†ïÎ≥¥ Ï†ÑÎã¨ÏùÑ ÏúÑÌïú Í∑∏ÎûòÌîΩ ÏöîÏÜå ÌôúÏö©")
    
    elif recommendation_type == "ÎßàÏºÄÌåÖ Ï†ÑÎûµ":
        st.success("üì¢ ÎßàÏºÄÌåÖ Ï†ÑÎûµ:")
        st.write("‚Ä¢ ÏÑ±Í≥µ ÏòÅÏÉÅÏùò ÌÇ§ÏõåÎìúÎ•º ÌôúÏö©Ìïú SEO ÏµúÏ†ÅÌôî")
        st.write("‚Ä¢ ÏãúÏ≤≠ÏûêÏôÄÏùò ÏÉÅÌò∏ÏûëÏö© Ï¶ùÎåÄ Î∞©Ïïà")
        st.write("‚Ä¢ ÏÜåÏÖúÎØ∏ÎîîÏñ¥ ÌÅ¨Î°úÏä§ ÌîÑÎ°úÎ™®ÏÖò")
    
    else:  # ÏàòÏùµÌôî Î∞©Î≤ï
        st.success("üí∞ ÏàòÏùµÌôî Ï†ÑÎûµ:")
        subscriber_count = channel_info.get('subscriber_count', 0)
        if subscriber_count < 1000:
            st.write("‚Ä¢ Íµ¨ÎèÖÏûê 1000Î™Ö Îã¨ÏÑ±ÏùÑ ÏúÑÌïú ÏΩòÌÖêÏ∏† ÏßëÏ§ë")
        else:
            st.write("‚Ä¢ Îã§ÏñëÌïú ÏàòÏùµÏõê Í∞úÎ∞ú (Ïä§Ìè∞ÏÑúÏã≠, Î©§Î≤ÑÏã≠)")
        st.write("‚Ä¢ Î∏åÎûúÎìú Í∞ÄÏπò Íµ¨Ï∂ïÏùÑ ÏúÑÌïú ÏùºÍ¥ÄÏÑ± ÏûàÎäî ÏΩòÌÖêÏ∏†")

def display_keywords_analysis(visualizer):
    """Display keyword and content analysis"""
    st.subheader("üî§ Keywords & Content Analysis")
    
    # Keyword analysis options
    analysis_source = st.selectbox(
        "ÌÇ§ÏõåÎìú Î∂ÑÏÑù ÎåÄÏÉÅ:",
        ["titles", "descriptions", "tags"],
        format_func=lambda x: {
            "titles": "üìù ÏòÅÏÉÅ Ï†úÎ™©",
            "descriptions": "üìÑ ÏÑ§Î™ÖÎûÄ",
            "tags": "üè∑Ô∏è ÌÉúÍ∑∏"
        }[x]
    )
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader(f"‚òÅÔ∏è ÏõåÎìú ÌÅ¥ÎùºÏö∞Îìú - { {'titles':'Ï†úÎ™©','descriptions':'ÏÑ§Î™Ö','tags':'ÌÉúÍ∑∏'}[analysis_source] }")
        wordcloud_fig = visualizer.create_wordcloud(source=analysis_source)
        if wordcloud_fig:
            st.pyplot(wordcloud_fig, use_container_width=True)
        else:
            st.info(f"{ {'titles':'Ï†úÎ™©','descriptions':'ÏÑ§Î™Ö','tags':'ÌÉúÍ∑∏'}[analysis_source] } Îç∞Ïù¥ÌÑ∞Í∞Ä Î∂ÄÏ°±ÌïòÏó¨ ÏõåÎìúÌÅ¥ÎùºÏö∞ÎìúÎ•º ÏÉùÏÑ±Ìï† Ïàò ÏóÜÏäµÎãàÎã§.")

    with col2:
        st.subheader(f"üìä Ï£ºÏöî ÌÇ§ÏõåÎìú - { {'titles':'Ï†úÎ™©','descriptions':'ÏÑ§Î™Ö','tags':'ÌÉúÍ∑∏'}[analysis_source] }")
        keywords_fig = visualizer.create_keywords_chart(source=analysis_source, top_n=20)
        if keywords_fig:
            st.plotly_chart(keywords_fig, use_container_width=True)
        else:
            st.info(f"{ {'titles':'Ï†úÎ™©','descriptions':'ÏÑ§Î™Ö','tags':'ÌÉúÍ∑∏'}[analysis_source] } Îç∞Ïù¥ÌÑ∞Í∞Ä Î∂ÄÏ°±ÌïòÏó¨ ÌÇ§ÏõåÎìú Î∂ÑÏÑùÏùÑ Ìï† Ïàò ÏóÜÏäµÎãàÎã§.")


    # ÏÑ±Í≥µ ÏòÅÏÉÅ Ìå®ÌÑ¥
    st.subheader("üéØ ÏÑ±Í≥µ ÏòÅÏÉÅ Ìå®ÌÑ¥")
    patterns = visualizer.analyze_successful_patterns()

    if patterns:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üî• Í≥†ÏÑ±Í≥º ÌÇ§ÏõåÎìú")
            if patterns.get('top_keywords'):
                for keyword, data in patterns['top_keywords'].items():
                    st.write(f"**{keyword}**: {data['count']}Í∞ú ÏòÅÏÉÅ, ÌèâÍ∑† {data['avg_views']:,.0f}Ìöå Ï°∞ÌöåÏàò")
        
        with col2:
            st.subheader("üìà ÏµúÏ†Å ÏóÖÎ°úÎìú ÏãúÍ∞Ñ")
            if patterns.get('best_times'):
                for time_info in patterns['best_times']:
                    st.write(f"**{time_info['period']}**: ÌèâÍ∑† {time_info['avg_views']:,.0f}Ìöå ({time_info['count']}Í∞ú ÏòÅÏÉÅ)")

def display_detailed_data():
    """Display detailed video data with filtering and sorting"""
    st.subheader("üìä ÏÉÅÏÑ∏ ÏòÅÏÉÅ Îç∞Ïù¥ÌÑ∞")
    
    videos_data = st.session_state.channel_data['videos']
    df = pd.DataFrame(videos_data)
    
    # Filters
    col1, col2, col3 = st.columns(3)
    
    with col1:
        video_type_filter = st.selectbox(
            "ÏòÅÏÉÅ Ïú†Ìòï",
            ["Ï†ÑÏ≤¥", "ÏáºÏ∏†", "Î°±Ìèº"],
            key="type_filter"
        )
    
    with col2:
        min_views = st.number_input(
            "ÏµúÏÜå Ï°∞ÌöåÏàò",
            min_value=0,
            value=0,
            key="min_views_filter"
        )
    
    with col3:
        date_range = st.date_input(
            "ÎÇ†Ïßú Î≤îÏúÑ",
            value=[],
            key="date_filter"
        )
    
    # Apply filters
    filtered_df = df.copy()
    
    if video_type_filter != "All":
        is_short = video_type_filter == "Shorts"
        filtered_df = filtered_df[filtered_df['is_short'] == is_short]
    
    if min_views > 0:
        filtered_df = filtered_df[filtered_df['view_count'] >= min_views]
    
    # Search functionality
    search_term = st.text_input("üîç Ï†úÎ™© ÎÇ¥ Í≤ÄÏÉâ", key="search_filter")
    if search_term:
        filtered_df = filtered_df[filtered_df['title'].str.contains(search_term, case=False, na=False)]
    
    # Display filtered data
    st.write(f"Showing {len(filtered_df)} of {len(df)} videos")
    
    # Select columns to display
    available_columns = ['title', 'published_at', 'view_count', 'like_count', 'comment_count', 
                        'duration_formatted', 'is_short', 'tags']
    selected_columns = st.multiselect(
        "ÌëúÏãúÌï† Ïª¨Îüº ÏÑ†ÌÉù",
        available_columns,
        default=['title', 'published_at', 'view_count', 'like_count', 'comment_count', 'duration_formatted'],
        key="column_selector"
    )
    
    if selected_columns:
        display_df = filtered_df[selected_columns].copy()
        
        # Format column names
        column_mapping = {
            'title': 'Ï†úÎ™©',
            'published_at': 'ÏóÖÎ°úÎìúÏùº',
            'view_count': 'Ï°∞ÌöåÏàò',
            'like_count': 'Ï¢ãÏïÑÏöî',
            'comment_count': 'ÎåìÍ∏ÄÏàò',
            'duration_formatted': 'Í∏∏Ïù¥',
            'is_short': 'Ïú†Ìòï',
            'tags': 'ÌÉúÍ∑∏'
        }
        
        display_df = display_df.rename(columns=column_mapping)
        
        if 'Type' in display_df.columns:
            display_df['Type'] = display_df['Type'].map({True: 'Shorts', False: 'Long-form'})
        
        st.dataframe(
            display_df,
            use_container_width=True,
            hide_index=True
        )

def display_export_options(visualizer):
    """Display export and reporting options"""
    st.subheader("üìã ÎÇ¥Î≥¥ÎÇ¥Í∏∞ Î∞è Î¶¨Ìè¨Ìä∏")
    
    videos_data = st.session_state.channel_data['videos']
    channel_info = st.session_state.channel_data['channel_info']
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Îç∞Ïù¥ÌÑ∞ ÎÇ¥Î≥¥ÎÇ¥Í∏∞")
        
        # CSV export
        if st.button("üìÑ CSVÎ°ú ÎÇ¥Î≥¥ÎÇ¥Í∏∞", use_container_width=True):
            df = pd.DataFrame(videos_data)
            csv = df.to_csv(index=False)
            st.download_button(
                label="üíæ Download CSV",
                data=csv,
                file_name=f"{channel_info.get('title', 'channel')}_analysis.csv",
                mime='text/csv',
                use_container_width=True
            )
        
        # JSON export
        if st.button("üìã JSONÏúºÎ°ú ÎÇ¥Î≥¥ÎÇ¥Í∏∞", use_container_width=True):
            import json
            json_data = json.dumps(st.session_state.channel_data, indent=2, default=str)
            st.download_button(
                label="üíæ Download JSON",
                data=json_data,
                file_name=f"{channel_info.get('title', 'channel')}_analysis.json",
                mime='application/json',
                use_container_width=True
            )
    
    with col2:
        st.subheader("üìà Î∂ÑÏÑù ÏöîÏïΩ")
        
        # Generate summary report
        summary = visualizer.generate_summary_report(channel_info)
        
        st.markdown("### üìã Channel Analysis Summary")
        for key, value in summary.items():
            if isinstance(value, dict):
                st.markdown(f"**{key}:**")
                for sub_key, sub_value in value.items():
                    st.markdown(f"  - {sub_key}: {sub_value}")
            else:
                st.markdown(f"**{key}:** {value}")
        
        # Export summary as text
        summary_text = "\n".join([f"{k}: {v}" for k, v in summary.items()])
        st.download_button(
            label="üìÑ ÏöîÏïΩ Î¶¨Ìè¨Ìä∏ Îã§Ïö¥Î°úÎìú",
            data=summary_text,
            file_name=f"{channel_info.get('title', 'Ï±ÑÎÑê')}_summary.txt",
            mime='text/plain',
            use_container_width=True
        )

if __name__ == "__main__":
    main()
