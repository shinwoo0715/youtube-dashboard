import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import numpy as np
from datetime import datetime, timedelta
import re
import io
import base64
from collections import Counter
import urllib.parse

from youtube_analyzer import YouTubeAnalyzer
from url_parser import YouTubeURLParser
from data_visualizer import DataVisualizer

# Page configuration
st.set_page_config(
    page_title="ğŸ“Š ìœ íŠœë¸Œ ì±„ë„ ì™„ì „ ë¶„ì„",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for modern UI/UX
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;500;600;700&display=swap');
    
    .main {
        font-family: 'Noto Sans KR', sans-serif;
    }
    
    .main-header {
        text-align: center;
        padding: 3rem 2rem;
        background: linear-gradient(135deg, #FF0000 0%, #FF6B6B 50%, #FF9999 100%);
        color: white;
        border-radius: 20px;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(255, 0, 0, 0.2);
        position: relative;
        overflow: hidden;
    }
    
    .main-header::before {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: linear-gradient(45deg, transparent, rgba(255,255,255,0.1), transparent);
        animation: shine 3s infinite;
    }
    
    @keyframes shine {
        0% { transform: translateX(-100%) translateY(-100%) rotate(30deg); }
        100% { transform: translateX(100%) translateY(100%) rotate(30deg); }
    }
    
    .main-header h1 {
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    .main-header p {
        font-size: 1.1rem;
        opacity: 0.9;
        font-weight: 400;
    }
    
    .metric-card {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        padding: 1.5rem;
        border-radius: 15px;
        border: 1px solid #e9ecef;
        margin: 0.75rem 0;
        box-shadow: 0 5px 15px rgba(0,0,0,0.08);
        transition: all 0.3s ease;
        position: relative;
        overflow: hidden;
    }
    
    .metric-card::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 4px;
        background: linear-gradient(90deg, #FF0000, #FF6B6B, #FF9999);
    }
    
    .metric-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.12);
    }
    
    .progress-container {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1.5rem 0;
        border: 1px solid #dee2e6;
        box-shadow: 0 5px 15px rgba(0,0,0,0.05);
    }
    
    .error-message {
        background: linear-gradient(135deg, #ffebee 0%, #ffcdd2 100%);
        color: #c62828;
        padding: 1.5rem;
        border-radius: 15px;
        border-left: 5px solid #c62828;
        margin: 1.5rem 0;
        box-shadow: 0 5px 15px rgba(198, 40, 40, 0.1);
        animation: slideIn 0.5s ease;
    }
    
    .success-message {
        background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
        color: #2e7d32;
        padding: 1.5rem;
        border-radius: 15px;
        border-left: 5px solid #2e7d32;
        margin: 1.5rem 0;
        box-shadow: 0 5px 15px rgba(46, 125, 50, 0.1);
        animation: slideIn 0.5s ease;
    }
    
    @keyframes slideIn {
        from { opacity: 0; transform: translateY(-10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .sidebar .stSelectbox, .sidebar .stTextInput, .sidebar .stTextArea {
        margin-bottom: 1.5rem;
    }
    
    .sidebar .stButton > button {
        width: 100%;
        height: 3rem;
        border-radius: 10px;
        font-weight: 600;
        font-size: 1.1rem;
        background: linear-gradient(135deg, #FF0000 0%, #FF6B6B 100%);
        border: none;
        color: white;
        transition: all 0.3s ease;
        box-shadow: 0 5px 15px rgba(255, 0, 0, 0.2);
    }
    
    .sidebar .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(255, 0, 0, 0.3);
    }
    
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 3rem;
        padding: 10px 20px;
        background: linear-gradient(135deg, #f8f9fa 0%, #ffffff 100%);
        border-radius: 10px;
        border: 1px solid #dee2e6;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #FF0000 0%, #FF6B6B 100%);
        color: white !important;
        box-shadow: 0 5px 15px rgba(255, 0, 0, 0.2);
    }
    
    .element-container .stMetric {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #e9ecef;
        box-shadow: 0 3px 10px rgba(0,0,0,0.05);
    }
    
    .feature-card {
        background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
        padding: 2rem;
        border-radius: 20px;
        border: 1px solid #e9ecef;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(0,0,0,0.08);
        transition: all 0.3s ease;
    }
    
    .feature-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 15px 35px rgba(0,0,0,0.15);
    }
    
    .feature-icon {
        font-size: 3rem;
        margin-bottom: 1rem;
        background: linear-gradient(135deg, #FF0000, #FF6B6B);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    @media (max-width: 768px) {
        .main-header h1 {
            font-size: 2rem;
        }
        
        .main-header {
            padding: 2rem 1rem;
        }
        
        .metric-card {
            font-size: 0.9rem;
            padding: 1rem;
        }
        
        .feature-card {
            padding: 1.5rem;
        }
    }
</style>
""", unsafe_allow_html=True)

def initialize_session_state():
    """Initialize session state variables"""
    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = None
    if 'channel_data' not in st.session_state:
        st.session_state.channel_data = None
    if 'analysis_complete' not in st.session_state:
        st.session_state.analysis_complete = False
    if 'progress_messages' not in st.session_state:
        st.session_state.progress_messages = []
    if 'error_message' not in st.session_state:
        st.session_state.error_message = None

def show_progress(message):
    """Add progress message to session state"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.progress_messages.append(f"[{timestamp}] {message}")

def display_progress():
    """Display progress messages"""
    if st.session_state.progress_messages:
        st.markdown('<div class="progress-container">', unsafe_allow_html=True)
        st.subheader("ğŸ“ˆ ë¶„ì„ ì§„í–‰ ìƒí™©")
        for message in st.session_state.progress_messages[-10:]:  # Show last 10 messages
            st.text(message)
        st.markdown('</div>', unsafe_allow_html=True)

def display_error(error_msg):
    """Display error message with styling"""
    st.markdown(f'<div class="error-message">âŒ <strong>ì˜¤ë¥˜:</strong> {error_msg}</div>', unsafe_allow_html=True)

def display_success(success_msg):
    """Display success message with styling"""
    st.markdown(f'<div class="success-message">âœ… <strong>ì„±ê³µ:</strong> {success_msg}</div>', unsafe_allow_html=True)

def main():
    initialize_session_state()
    
    # Main header
    st.markdown('<div class="main-header"><h1>ğŸ“Š ìœ íŠœë¸Œ ì±„ë„ ì™„ì „ ë¶„ì„</h1><p>ëª¨ë“  ìœ íŠœë¸Œ ì±„ë„ì˜ ì™„ë²½í•œ ë°ì´í„° ë¶„ì„ ë„êµ¬</p></div>', unsafe_allow_html=True)
    
    # Sidebar for inputs
    with st.sidebar:
        st.header("ğŸ”§ ì„¤ì •")
        
        # API Key input
        st.subheader("ğŸ”‘ YouTube Data API í‚¤")
        api_key = st.text_input(
            "YouTube Data API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            type="password",
            help="Google Cloud Consoleì—ì„œ YouTube Data API v3 í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”"
        )
        
        if not api_key:
            st.warning("âš ï¸ ì§„í–‰í•˜ë ¤ë©´ YouTube Data API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            st.markdown("""
            **API í‚¤ ë°œê¸‰ ë°©ë²•:**
            1. [Google Cloud Console](https://console.cloud.google.com/) ì ‘ì†
            2. ìƒˆ í”„ë¡œì íŠ¸ ìƒì„± ë˜ëŠ” ê¸°ì¡´ í”„ë¡œì íŠ¸ ì„ íƒ
            3. YouTube Data API v3 í™œì„±í™”
            4. ì‚¬ìš©ì ì¸ì¦ ì •ë³´ ìƒì„± (API í‚¤)
            5. ìœ„ì— í‚¤ë¥¼ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸°
            """)
        
        # Channel input
        st.subheader("ğŸ“º ì±„ë„ ì •ë³´")
        channel_input = st.text_input(
            "ì±„ë„ëª… ë˜ëŠ” URL",
            placeholder="ì˜ˆ: ì¹™ì¹™í’‰í’‰ ë˜ëŠ” https://www.youtube.com/@ì¹™ì¹™í’‰í’‰",
            help="ì±„ë„ëª…, @í•¸ë“¤, ë˜ëŠ” ëª¨ë“  í˜•íƒœì˜ ìœ íŠœë¸Œ ì±„ë„ URLì„ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        # Advanced Analysis options
        st.subheader("âš™ï¸ ê³ ê¸‰ ë¶„ì„ ì˜µì…˜")
        
        # Basic options
        with st.expander("ğŸ“Š ê¸°ë³¸ ì„¤ì •", expanded=True):
            max_videos = st.selectbox(
                "ë¶„ì„í•  ìµœëŒ€ ì˜ìƒ ìˆ˜",
                [50, 100, 200, 500, 1000, 2000],
                index=2,
                help="ë” ë§ì€ ì˜ìƒ = ë” ì •í™•í•œ ë¶„ì„ (ì²˜ë¦¬ ì‹œê°„ ì¦ê°€)"
            )
            
            col1, col2 = st.columns(2)
            with col1:
                include_shorts = st.checkbox("ì‡¼ì¸  í¬í•¨", value=True)
            with col2:
                include_long_form = st.checkbox("ë¡±í¼ í¬í•¨", value=True)
        
        # Date range filter
        with st.expander("ğŸ“… ë‚ ì§œ í•„í„°"):
            use_date_filter = st.checkbox("ë‚ ì§œ ë²”ìœ„ ì„¤ì •")
            if use_date_filter:
                date_from = st.date_input("ì‹œì‘ ë‚ ì§œ", value=datetime.now() - timedelta(days=365))
                date_to = st.date_input("ì¢…ë£Œ ë‚ ì§œ", value=datetime.now())
        
        # Performance filters
        with st.expander("ğŸ¯ ì„±ê³¼ í•„í„°"):
            min_views = st.number_input("ìµœì†Œ ì¡°íšŒìˆ˜", min_value=0, value=0)
            min_likes = st.number_input("ìµœì†Œ ì¢‹ì•„ìš” ìˆ˜", min_value=0, value=0)
            
        # Analysis depth
        with st.expander("ğŸ” ë¶„ì„ ê¹Šì´"):
            analyze_thumbnails = st.checkbox("ì¸ë„¤ì¼ ìƒ‰ìƒ ë¶„ì„", value=True)
            analyze_sentiment = st.checkbox("ì œëª© ê°ì • ë¶„ì„", value=True)
            predict_trends = st.checkbox("íŠ¸ë Œë“œ ì˜ˆì¸¡", value=True)
            competitor_analysis = st.checkbox("ê²½ìŸì ë¶„ì„ (ë² íƒ€)", value=False)
        
        # Export options
        with st.expander("ğŸ’¾ ë‚´ë³´ë‚´ê¸° ì„¤ì •"):
            export_format = st.selectbox("ë‚´ë³´ë‚´ê¸° í˜•ì‹", ["Excel", "CSV", "JSON"])
            include_charts = st.checkbox("ì°¨íŠ¸ ì´ë¯¸ì§€ í¬í•¨", value=True)
        
        st.divider()
        
        # Analysis button
        analyze_button = st.button(
            "ğŸš€ ë¶„ì„ ì‹œì‘",
            type="primary",
            disabled=not (api_key and channel_input),
            use_container_width=True
        )
    
    # Main content area
    if analyze_button and api_key and channel_input:
        st.session_state.progress_messages = []
        st.session_state.error_message = None
        st.session_state.analysis_complete = False
        
        # Initialize analyzer
        show_progress("ìœ íŠœë¸Œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
        st.session_state.analyzer = YouTubeAnalyzer(api_key)
        
        # Parse channel input
        show_progress("ì±„ë„ ì •ë³´ íŒŒì‹± ì¤‘...")
        parser = YouTubeURLParser()
        
        try:
            channel_info = parser.parse_channel_input(channel_input)
            show_progress(f"ì±„ë„ íŒŒì‹± ì™„ë£Œ: {channel_info}")
            
            # Get channel data
            show_progress("ì±„ë„ ì„¸ë¶€ ì •ë³´ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            channel_data = st.session_state.analyzer.get_channel_info(channel_info)
            
            if not channel_data:
                display_error("ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì±„ë„ëª…ì´ë‚˜ URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return
            
            show_progress(f"ì±„ë„ ë°œê²¬: {channel_data.get('title', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
            
            # Create progress container
            progress_container = st.container()
            with progress_container:
                display_progress()
            
            # Collect video data
            show_progress("ì˜ìƒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # Create a progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def progress_callback(current, total, message):
                progress = min(current / total, 1.0) if total > 0 else 0
                progress_bar.progress(progress)
                status_text.text(f"{message} ({current}/{total})")
                show_progress(f"{message} ({current}/{total})")
            
            videos_data = st.session_state.analyzer.collect_all_videos(
                channel_data['id'],
                max_results=max_videos,
                include_shorts=include_shorts,
                include_long_form=include_long_form,
                progress_callback=progress_callback
            )
            
            if not videos_data:
                display_error("ì´ ì±„ë„ì—ì„œ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            progress_bar.progress(1.0)
            status_text.text(f"ë¶„ì„ ì™„ë£Œ! {len(videos_data)}ê°œ ì˜ìƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
            
            # Store data in session state
            st.session_state.channel_data = {
                'channel_info': channel_data,
                'videos': videos_data
            }
            st.session_state.analysis_complete = True
            
            display_success(f"{channel_data.get('title', 'ì•Œ ìˆ˜ ì—†ëŠ”')} ì±„ë„ì˜ {len(videos_data)}ê°œ ì˜ìƒ ë¶„ì„ì„ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            display_error(f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {str(e)}")
            return
    
    # Display results if analysis is complete
    if st.session_state.analysis_complete and st.session_state.channel_data:
        display_analysis_results()

def display_analysis_results():
    """Display comprehensive analysis results"""
    channel_info = st.session_state.channel_data['channel_info']
    videos_data = st.session_state.channel_data['videos']
    
    # Create visualizer
    visualizer = DataVisualizer(videos_data)
    
    st.header(f"ğŸ“Š {channel_info.get('title', 'ì•Œ ìˆ˜ ì—†ëŠ” ì±„ë„')} ë¶„ì„ ê²°ê³¼")
    
    # Channel overview with enhanced metrics
    col1, col2, col3, col4 = st.columns(4)
    
    total_videos = len(videos_data)
    total_views = sum(video.get('view_count', 0) for video in videos_data)
    total_likes = sum(video.get('like_count', 0) for video in videos_data)
    total_comments = sum(video.get('comment_count', 0) for video in videos_data)
    avg_views = total_views / total_videos if total_videos > 0 else 0
    
    shorts_count = sum(1 for video in videos_data if video.get('is_short', False))
    long_form_count = total_videos - shorts_count
    
    # Calculate engagement metrics
    total_engagement = total_likes + total_comments
    avg_engagement_rate = (total_engagement / total_views * 100) if total_views > 0 else 0
    
    with col1:
        st.metric("ì´ ì˜ìƒ ìˆ˜", f"{total_videos:,}")
        st.metric("ì‡¼ì¸ ", f"{shorts_count:,}")
    
    with col2:
        st.metric("ì´ ì¡°íšŒìˆ˜", f"{total_views:,}")
        st.metric("í‰ê·  ì¡°íšŒìˆ˜", f"{avg_views:,.0f}")
    
    with col3:
        st.metric("ì´ ì¢‹ì•„ìš”", f"{total_likes:,}")
        st.metric("ë¡±í¼", f"{long_form_count:,}")
    
    with col4:
        subscriber_count = channel_info.get('subscriber_count', 0)
        video_count = channel_info.get('video_count', 0)
        st.metric("êµ¬ë…ì ìˆ˜", f"{subscriber_count:,}")
        st.metric("ì±„ë„ ì´ ì˜ìƒ", f"{video_count:,}")
    
    # Additional metrics row
    col5, col6, col7, col8 = st.columns(4)
    
    with col5:
        st.metric("ì´ ëŒ“ê¸€", f"{total_comments:,}")
    
    with col6:
        st.metric("í‰ê·  ì°¸ì—¬ìœ¨", f"{avg_engagement_rate:.2f}%")
    
    with col7:
        # Calculate average upload frequency
        if total_videos > 1:
            date_range = (max(video['published_at'] for video in videos_data) - 
                         min(video['published_at'] for video in videos_data)).days
            upload_frequency = date_range / total_videos if date_range > 0 else 0
            st.metric("í‰ê·  ì—…ë¡œë“œ ê°„ê²©", f"{upload_frequency:.1f}ì¼")
        else:
            st.metric("í‰ê·  ì—…ë¡œë“œ ê°„ê²©", "N/A")
    
    with col8:
        # Most successful video
        if videos_data:
            best_video = max(videos_data, key=lambda x: x.get('view_count', 0))
            st.metric("ìµœê³  ì¡°íšŒìˆ˜", f"{best_video.get('view_count', 0):,}")
    
    # Create enhanced analysis tabs
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
        "ğŸ“ˆ ì„±ê³¼ ê°œìš”",
        "ğŸ“… ì—…ë¡œë“œ íŒ¨í„´", 
        "ğŸ”¥ ì¸ê¸° ì˜ìƒ",
        "ğŸ”¤ í‚¤ì›Œë“œ ë¶„ì„",
        "ğŸ¯ ì„±ê³µ íŒ¨í„´",
        "ğŸ“Š ìƒì„¸ ë°ì´í„°",
        "ğŸ”® íŠ¸ë Œë“œ ì˜ˆì¸¡",
        "ğŸ“‹ ë‚´ë³´ë‚´ê¸° & ë¦¬í¬íŠ¸"
    ])
    
    with tab1:
        display_performance_overview(visualizer)
    
    with tab2:
        display_upload_patterns(visualizer)
    
    with tab3:
        display_top_videos(visualizer)
    
    with tab4:
        display_keywords_analysis(visualizer)
    
    with tab5:
        display_success_patterns(visualizer)
    
    with tab6:
        display_detailed_data()
    
    with tab7:
        display_trend_prediction(visualizer)
    
    with tab8:
        display_export_options(visualizer)

def display_performance_overview(visualizer):
    """Display performance overview charts"""
    st.subheader("ğŸ“ˆ ì„±ê³¼ ê°œìš”")
    
    # Views distribution
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ì¡°íšŒìˆ˜ ë¶„í¬")
        fig = visualizer.create_views_distribution()
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("ì°¸ì—¬ìœ¨ ë¶„ì„")
        fig = visualizer.create_engagement_chart()
        st.plotly_chart(fig, use_container_width=True)
    
    # Performance comparison: Shorts vs Long-form
    st.subheader("ğŸ“Š ì‡¼ì¸  vs ë¡±í¼ ì„±ê³¼ ë¹„êµ")
    fig = visualizer.create_shorts_vs_longform_comparison()
    st.plotly_chart(fig, use_container_width=True)
    
    # Duration vs Views correlation
    st.subheader("â±ï¸ ì˜ìƒ ê¸¸ì´ì™€ ì¡°íšŒìˆ˜ ìƒê´€ê´€ê³„")
    fig = visualizer.create_duration_views_correlation()
    st.plotly_chart(fig, use_container_width=True)

def display_upload_patterns(visualizer):
    """Display upload pattern analysis"""
    st.subheader("ğŸ“… ì—…ë¡œë“œ íŒ¨í„´ ë¶„ì„")
    
    # Monthly upload trends
    st.subheader("ğŸ“Š ì›”ë³„ ì—…ë¡œë“œ íŠ¸ë Œë“œ")
    fig = visualizer.create_monthly_trends()
    st.plotly_chart(fig, use_container_width=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“… ìš”ì¼ë³„ ì—…ë¡œë“œ íŒ¨í„´")
        fig = visualizer.create_weekday_analysis()
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("ğŸ• ì‹œê°„ëŒ€ë³„ ì—…ë¡œë“œ íŒ¨í„´")
        fig = visualizer.create_hourly_analysis()
        st.plotly_chart(fig, use_container_width=True)
    
    # Upload consistency analysis
    st.subheader("ğŸ“ˆ ì—…ë¡œë“œ ì¼ê´€ì„± ë¶„ì„")
    consistency_data = visualizer.analyze_upload_consistency()
    
    # Display consistency data in a more user-friendly format
    if 'error' not in consistency_data:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ì´ ì˜ìƒ ìˆ˜", f"{consistency_data['total_videos']:,}")
            st.metric("í™œë™ ê¸°ê°„", f"{consistency_data['date_range']['days_active']}ì¼")
        
        with col2:
            st.metric("í‰ê·  ì—…ë¡œë“œ ê°„ê²©", f"{consistency_data['upload_frequency']['average_gap_days']:.1f}ì¼")
            st.metric("ì£¼ë‹¹ ì—…ë¡œë“œ ìˆ˜", f"{consistency_data['upload_patterns']['uploads_per_week']:.1f}ê°œ")
        
        with col3:
            st.metric("ê°€ì¥ í™œë°œí•œ ìš”ì¼", consistency_data['upload_patterns']['most_active_day'])
            st.metric("ì£¼ìš” ì—…ë¡œë“œ ì‹œê°„", f"{consistency_data['upload_patterns']['most_active_hour']}ì‹œ")
    else:
        st.error("ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

def display_top_videos(visualizer):
    """Display top performing videos"""
    st.subheader("ğŸ”¥ ì¸ê¸° ì˜ìƒ ë¶„ì„")
    
    # Top videos by different metrics
    metric_type = st.selectbox(
        "ìƒìœ„ ì˜ìƒ ì •ë ¬ ê¸°ì¤€ ì„ íƒ",
        ["view_count", "like_count", "comment_count", "engagement_rate"],
        format_func=lambda x: {
            "view_count": "ğŸ‘ï¸ ì¡°íšŒìˆ˜",
            "like_count": "ğŸ‘ ì¢‹ì•„ìš”", 
            "comment_count": "ğŸ’¬ ëŒ“ê¸€ìˆ˜",
            "engagement_rate": "ğŸ“Š ì°¸ì—¬ìœ¨"
        }[x]
    )
    
    # Number of top videos to display
    top_count = st.slider("í‘œì‹œí•  ìƒìœ„ ì˜ìƒ ìˆ˜", min_value=5, max_value=50, value=20)
    
    top_videos = visualizer.get_top_videos(metric=metric_type, count=top_count)
    
    # Display top videos table
    if top_videos:
        df = pd.DataFrame(top_videos)
        
        # Format the dataframe for display
        display_df = df[['title', 'published_at', 'view_count', 'like_count', 'comment_count', 'duration_formatted', 'is_short']].copy()
        display_df.columns = ['ì œëª©', 'ì—…ë¡œë“œì¼', 'ì¡°íšŒìˆ˜', 'ì¢‹ì•„ìš”', 'ëŒ“ê¸€ìˆ˜', 'ê¸¸ì´', 'ìœ í˜•']
        display_df['ìœ í˜•'] = display_df['ìœ í˜•'].apply(lambda x: 'ì‡¼ì¸ ' if x else 'ë¡±í¼')
        
        # Format numbers with commas
        for col in ['ì¡°íšŒìˆ˜', 'ì¢‹ì•„ìš”', 'ëŒ“ê¸€ìˆ˜']:
            if col in display_df.columns:
                display_df[col] = display_df[col].apply(lambda x: f"{x:,}" if isinstance(x, (int, float)) else x)
        
        st.dataframe(
            display_df,
            use_container_width=True,
            hide_index=True
        )
        
        # Top video performance chart
        metric_name = {
            "view_count": "ì¡°íšŒìˆ˜",
            "like_count": "ì¢‹ì•„ìš”",
            "comment_count": "ëŒ“ê¸€ìˆ˜",
            "engagement_rate": "ì°¸ì—¬ìœ¨"
        }[metric_type]
        
        st.subheader(f"ğŸ“Š {metric_name} ê¸°ì¤€ ìƒìœ„ 10ê°œ ì˜ìƒ")
        fig = visualizer.create_top_videos_chart(metric=metric_type, count=10)
        st.plotly_chart(fig, use_container_width=True)
        
        # Performance insights
        if len(top_videos) >= 3:
            st.subheader("ğŸ’¡ ì¸ê¸° ì˜ìƒ ì¸ì‚¬ì´íŠ¸")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ìƒìœ„ 3ê°œ ì˜ìƒ í‰ê·  ì„±ê³¼:**")
                top_3 = top_videos[:3]
                avg_views = sum(v['view_count'] for v in top_3) / 3
                avg_likes = sum(v['like_count'] for v in top_3) / 3
                avg_comments = sum(v['comment_count'] for v in top_3) / 3
                
                st.metric("í‰ê·  ì¡°íšŒìˆ˜", f"{avg_views:,.0f}")
                st.metric("í‰ê·  ì¢‹ì•„ìš”", f"{avg_likes:,.0f}")
                st.metric("í‰ê·  ëŒ“ê¸€", f"{avg_comments:,.0f}")
            
            with col2:
                st.write("**ì¸ê¸° ì˜ìƒ ìœ í˜• ë¶„í¬:**")
                shorts_in_top = sum(1 for v in top_videos[:10] if v.get('is_short', False))
                longform_in_top = 10 - shorts_in_top
                
                st.metric("ìƒìœ„ 10ê°œ ì¤‘ ì‡¼ì¸ ", f"{shorts_in_top}ê°œ")
                st.metric("ìƒìœ„ 10ê°œ ì¤‘ ë¡±í¼", f"{longform_in_top}ê°œ")
    else:
        st.info("í‘œì‹œí•  ì˜ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

def display_success_patterns(visualizer):
    """Display analysis of successful video patterns"""
    st.subheader("ğŸ¯ ì„±ê³µ íŒ¨í„´ ë¶„ì„")
    
    # Get successful patterns
    patterns = visualizer.analyze_successful_patterns()
    
    if patterns and 'top_keywords' in patterns:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ”¥ ê³ ì„±ê³¼ í‚¤ì›Œë“œ")
            if patterns.get('top_keywords'):
                keywords_data = []
                for keyword, data in list(patterns['top_keywords'].items())[:10]:
                    keywords_data.append({
                        'í‚¤ì›Œë“œ': keyword,
                        'ì˜ìƒìˆ˜': data['count'],
                        'í‰ê·  ì¡°íšŒìˆ˜': f"{data['avg_views']:,.0f}",
                        'ì´ ì¡°íšŒìˆ˜': f"{data['total_views']:,.0f}"
                    })
                
                if keywords_data:
                    st.dataframe(pd.DataFrame(keywords_data), use_container_width=True, hide_index=True)
                else:
                    st.info("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ë¶„ì„í•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        with col2:
            st.subheader("ğŸ“ˆ ìµœì  ì—…ë¡œë“œ ì‹œê°„")
            if patterns.get('best_times'):
                times_data = []
                for time_info in patterns['best_times'][:5]:
                    times_data.append({
                        'ì‹œê°„ëŒ€': f"{time_info['hour']}ì‹œ",
                        'ì˜ìƒìˆ˜': time_info['count'],
                        'í‰ê·  ì¡°íšŒìˆ˜': f"{time_info['avg_views']:,.0f}"
                    })
                
                if times_data:
                    st.dataframe(pd.DataFrame(times_data), use_container_width=True, hide_index=True)
                else:
                    st.info("ì‹œê°„ëŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ì—…ë¡œë“œ ì‹œê°„ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # Best performing video length analysis
    st.subheader("â±ï¸ ìµœì  ì˜ìƒ ê¸¸ì´ ë¶„ì„")
    videos_data = visualizer.videos_data
    if videos_data:
        # Group by duration ranges
        duration_ranges = []
        for video in videos_data:
            duration = video.get('duration_seconds', 0)
            if duration <= 60:
                range_name = "ì‡¼ì¸  (â‰¤60ì´ˆ)"
            elif duration <= 300:
                range_name = "ë‹¨í¸ (1-5ë¶„)"
            elif duration <= 600:
                range_name = "ì¤‘í¸ (5-10ë¶„)"
            elif duration <= 1200:
                range_name = "ì¥í¸ (10-20ë¶„)"
            else:
                range_name = "ì¥ì‹œê°„ (>20ë¶„)"
            
            duration_ranges.append({
                'range': range_name,
                'views': video.get('view_count', 0),
                'likes': video.get('like_count', 0),
                'comments': video.get('comment_count', 0)
            })
        
        if duration_ranges:
            df_duration = pd.DataFrame(duration_ranges)
            duration_summary = df_duration.groupby('range').agg({
                'views': ['count', 'mean', 'median'],
                'likes': 'mean',
                'comments': 'mean'
            }).round(0)
            
            duration_summary.columns = ['ì˜ìƒìˆ˜', 'í‰ê· ì¡°íšŒìˆ˜', 'ì¤‘ê°„ì¡°íšŒìˆ˜', 'í‰ê· ì¢‹ì•„ìš”', 'í‰ê· ëŒ“ê¸€']
            duration_summary = duration_summary.reset_index()
            duration_summary.columns = ['ê¸¸ì´ë²”ìœ„', 'ì˜ìƒìˆ˜', 'í‰ê· ì¡°íšŒìˆ˜', 'ì¤‘ê°„ì¡°íšŒìˆ˜', 'í‰ê· ì¢‹ì•„ìš”', 'í‰ê· ëŒ“ê¸€']
            
            # Format numbers
            for col in ['ì˜ìƒìˆ˜', 'í‰ê· ì¡°íšŒìˆ˜', 'ì¤‘ê°„ì¡°íšŒìˆ˜', 'í‰ê· ì¢‹ì•„ìš”', 'í‰ê· ëŒ“ê¸€']:
                duration_summary[col] = duration_summary[col].apply(lambda x: f"{int(x):,}")
            
            st.dataframe(duration_summary, use_container_width=True, hide_index=True)
    
    # Title pattern analysis
    st.subheader("ğŸ“ ì œëª© íŒ¨í„´ ë¶„ì„")
    if videos_data:
        # Analyze title characteristics of top performing videos
        top_videos = sorted(videos_data, key=lambda x: x.get('view_count', 0), reverse=True)[:20]
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            avg_title_length = sum(len(v.get('title', '')) for v in top_videos) / len(top_videos)
            st.metric("ìƒìœ„ ì˜ìƒ í‰ê·  ì œëª© ê¸¸ì´", f"{avg_title_length:.0f}ì")
        
        with col2:
            question_titles = sum(1 for v in top_videos if '?' in v.get('title', ''))
            st.metric("ë¬¼ìŒí‘œ í¬í•¨ ì œëª©", f"{question_titles}ê°œ")
        
        with col3:
            exclamation_titles = sum(1 for v in top_videos if '!' in v.get('title', ''))
            st.metric("ëŠë‚Œí‘œ í¬í•¨ ì œëª©", f"{exclamation_titles}ê°œ")

def display_trend_prediction(visualizer):
    """Display trend prediction and future insights"""
    st.subheader("ğŸ”® íŠ¸ë Œë“œ ì˜ˆì¸¡ ë° ì¸ì‚¬ì´íŠ¸")
    
    videos_data = visualizer.videos_data
    if not videos_data or len(videos_data) < 10:
        st.warning("íŠ¸ë Œë“œ ì˜ˆì¸¡ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 10ê°œ ì´ìƒì˜ ì˜ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    # Growth trend analysis
    st.subheader("ğŸ“ˆ ì„±ì¥ íŠ¸ë Œë“œ ë¶„ì„")
    
    # Sort videos by date
    sorted_videos = sorted(videos_data, key=lambda x: x.get('published_at'))
    
    # Calculate monthly growth
    monthly_data = {}
    for video in sorted_videos:
        month_key = video['published_at'].strftime('%Y-%m')
        if month_key not in monthly_data:
            monthly_data[month_key] = {
                'count': 0,
                'total_views': 0,
                'total_likes': 0,
                'total_comments': 0
            }
        monthly_data[month_key]['count'] += 1
        monthly_data[month_key]['total_views'] += video.get('view_count', 0)
        monthly_data[month_key]['total_likes'] += video.get('like_count', 0)
        monthly_data[month_key]['total_comments'] += video.get('comment_count', 0)
    
    if len(monthly_data) >= 3:
        months = sorted(monthly_data.keys())
        recent_months = months[-3:]
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            recent_avg_views = sum(monthly_data[m]['total_views'] for m in recent_months) / len(recent_months)
            older_months = months[:-3] if len(months) > 3 else months[:3]
            older_avg_views = sum(monthly_data[m]['total_views'] for m in older_months) / len(older_months) if older_months else recent_avg_views
            
            growth_rate = ((recent_avg_views - older_avg_views) / older_avg_views * 100) if older_avg_views > 0 else 0
            st.metric("ìµœê·¼ 3ê°œì›” ì„±ì¥ë¥ ", f"{growth_rate:+.1f}%")
        
        with col2:
            recent_upload_count = sum(monthly_data[m]['count'] for m in recent_months)
            st.metric("ìµœê·¼ 3ê°œì›” ì—…ë¡œë“œ", f"{recent_upload_count}ê°œ")
        
        with col3:
            if len(recent_months) >= 2:
                last_month_views = monthly_data[recent_months[-1]]['total_views']
                prev_month_views = monthly_data[recent_months[-2]]['total_views']
                month_growth = ((last_month_views - prev_month_views) / prev_month_views * 100) if prev_month_views > 0 else 0
                st.metric("ì „ì›” ëŒ€ë¹„ ì„±ì¥ë¥ ", f"{month_growth:+.1f}%")
    
    # Content recommendations
    st.subheader("ğŸ’¡ ì½˜í…ì¸  ì¶”ì²œ")
    
    # Analyze successful content patterns
    top_performing = sorted(videos_data, key=lambda x: x.get('view_count', 0), reverse=True)[:10]
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ì„±ê³µ ìš”ì¸ ë¶„ì„:**")
        
        # Most successful video type
        shorts_performance = [v for v in top_performing if v.get('is_short', False)]
        longform_performance = [v for v in top_performing if not v.get('is_short', False)]
        
        if len(shorts_performance) > len(longform_performance):
            st.info("ğŸ¯ ì‡¼ì¸  ì½˜í…ì¸ ê°€ ë” ë†’ì€ ì„±ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤")
        else:
            st.info("ğŸ¯ ë¡±í¼ ì½˜í…ì¸ ê°€ ë” ë†’ì€ ì„±ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤")
        
        # Best upload day
        day_performance = {}
        for video in top_performing:
            day = video['published_at'].strftime('%A')
            if day not in day_performance:
                day_performance[day] = 0
            day_performance[day] += 1
        
        if day_performance:
            best_day = max(day_performance.keys(), key=lambda x: day_performance[x])
            day_names = {
                'Monday': 'ì›”ìš”ì¼', 'Tuesday': 'í™”ìš”ì¼', 'Wednesday': 'ìˆ˜ìš”ì¼',
                'Thursday': 'ëª©ìš”ì¼', 'Friday': 'ê¸ˆìš”ì¼', 'Saturday': 'í† ìš”ì¼', 'Sunday': 'ì¼ìš”ì¼'
            }
            st.info(f"ğŸ“… {day_names.get(best_day, best_day)}ì— ì—…ë¡œë“œí•œ ì˜ìƒì˜ ì„±ê³¼ê°€ ì¢‹ìŠµë‹ˆë‹¤")
    
    with col2:
        st.write("**ê°œì„  ì œì•ˆ:**")
        
        # Upload consistency
        upload_gaps = []
        for i in range(1, len(sorted_videos)):
            gap = (sorted_videos[i]['published_at'] - sorted_videos[i-1]['published_at']).days
            upload_gaps.append(gap)
        
        if upload_gaps:
            avg_gap = sum(upload_gaps) / len(upload_gaps)
            if avg_gap > 7:
                st.warning("âš¡ ì—…ë¡œë“œ ì£¼ê¸°ë¥¼ ë” ì§§ê²Œ í•˜ë©´ ì„±ì¥ì— ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            elif avg_gap < 1:
                st.warning("â° ë„ˆë¬´ ìì£¼ ì—…ë¡œë“œí•˜ë©´ í’ˆì§ˆì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            else:
                st.success("âœ… ì ì ˆí•œ ì—…ë¡œë“œ ì£¼ê¸°ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤")
        
        # Engagement rate analysis
        recent_videos = sorted_videos[-10:] if len(sorted_videos) >= 10 else sorted_videos
        avg_engagement = sum(v.get('engagement_rate', 0) for v in recent_videos) / len(recent_videos)
        
        if avg_engagement < 2:
            st.warning("ğŸ’¬ ì‹œì²­ì ì°¸ì—¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ëŒ“ê¸€ì„ ìœ ë„í•˜ëŠ” ì§ˆë¬¸ì´ë‚˜ ìƒí˜¸ì‘ìš©ì„ ëŠ˜ë ¤ë³´ì„¸ìš”")
        elif avg_engagement > 5:
            st.success("ğŸ”¥ ë†’ì€ ì°¸ì—¬ë„ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤!")
        else:
            st.info("ğŸ“Š í‰ê· ì ì¸ ì°¸ì—¬ë„ì…ë‹ˆë‹¤. ë” ë§ì€ ìƒí˜¸ì‘ìš©ì„ ì‹œë„í•´ë³´ì„¸ìš”")

def display_keywords_analysis(visualizer):
    """Display keyword and content analysis"""
    st.subheader("ğŸ”¤ Keywords & Content Analysis")
    
    # Keyword analysis options
    analysis_source = st.selectbox(
        "Analyze keywords from:",
        ["titles", "descriptions", "tags"],
        format_func=lambda x: {
            "titles": "ğŸ“ Video Titles",
            "descriptions": "ğŸ“„ Descriptions",
            "tags": "ğŸ·ï¸ Tags"
        }[x]
    )
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader(f"â˜ï¸ Word Cloud - {analysis_source.title()}")
        wordcloud_fig = visualizer.create_wordcloud(source=analysis_source)
        if wordcloud_fig:
            st.pyplot(wordcloud_fig, use_container_width=True)
        else:
            st.info(f"No {analysis_source} data available for word cloud generation.")
    
    with col2:
        st.subheader(f"ğŸ“Š Top Keywords - {analysis_source.title()}")
        keywords_fig = visualizer.create_keywords_chart(source=analysis_source, top_n=20)
        if keywords_fig:
            st.plotly_chart(keywords_fig, use_container_width=True)
        else:
            st.info(f"No {analysis_source} data available for keyword analysis.")
    
    # Successful video patterns
    st.subheader("ğŸ¯ Successful Video Patterns")
    patterns = visualizer.analyze_successful_patterns()
    
    if patterns:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ”¥ High-performing Keywords")
            if patterns.get('top_keywords'):
                for keyword, data in patterns['top_keywords'].items():
                    st.write(f"**{keyword}**: {data['count']} videos, avg {data['avg_views']:,.0f} views")
        
        with col2:
            st.subheader("ğŸ“ˆ Best Upload Times")
            if patterns.get('best_times'):
                for time_info in patterns['best_times']:
                    st.write(f"**{time_info['period']}**: Avg {time_info['avg_views']:,.0f} views ({time_info['count']} videos)")

def display_detailed_data():
    """Display detailed video data with filtering and sorting"""
    st.subheader("ğŸ“Š Detailed Video Data")
    
    videos_data = st.session_state.channel_data['videos']
    df = pd.DataFrame(videos_data)
    
    # Filters
    col1, col2, col3 = st.columns(3)
    
    with col1:
        video_type_filter = st.selectbox(
            "Video Type",
            ["All", "Shorts", "Long-form"],
            key="type_filter"
        )
    
    with col2:
        min_views = st.number_input(
            "Minimum Views",
            min_value=0,
            value=0,
            key="min_views_filter"
        )
    
    with col3:
        date_range = st.date_input(
            "Date Range",
            value=[],
            key="date_filter"
        )
    
    # Apply filters
    filtered_df = df.copy()
    
    if video_type_filter != "All":
        is_short = video_type_filter == "Shorts"
        filtered_df = filtered_df[filtered_df['is_short'] == is_short]
    
    if min_views > 0:
        filtered_df = filtered_df[filtered_df['view_count'] >= min_views]
    
    # Search functionality
    search_term = st.text_input("ğŸ” Search in titles", key="search_filter")
    if search_term:
        filtered_df = filtered_df[filtered_df['title'].str.contains(search_term, case=False, na=False)]
    
    # Display filtered data
    st.write(f"Showing {len(filtered_df)} of {len(df)} videos")
    
    # Select columns to display
    available_columns = ['title', 'published_at', 'view_count', 'like_count', 'comment_count', 
                        'duration_formatted', 'is_short', 'tags']
    selected_columns = st.multiselect(
        "Select columns to display",
        available_columns,
        default=['title', 'published_at', 'view_count', 'like_count', 'comment_count', 'duration_formatted'],
        key="column_selector"
    )
    
    if selected_columns:
        display_df = filtered_df[selected_columns].copy()
        
        # Format column names
        column_mapping = {
            'title': 'Title',
            'published_at': 'Published',
            'view_count': 'Views',
            'like_count': 'Likes',
            'comment_count': 'Comments',
            'duration_formatted': 'Duration',
            'is_short': 'Type',
            'tags': 'Tags'
        }
        
        display_df = display_df.rename(columns=column_mapping)
        
        if 'Type' in display_df.columns:
            display_df['Type'] = display_df['Type'].map({True: 'Shorts', False: 'Long-form'})
        
        st.dataframe(
            display_df,
            use_container_width=True,
            hide_index=True
        )

def display_export_options(visualizer):
    """Display export and reporting options"""
    st.subheader("ğŸ“‹ Export & Reports")
    
    videos_data = st.session_state.channel_data['videos']
    channel_info = st.session_state.channel_data['channel_info']
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š Data Export")
        
        # CSV export
        if st.button("ğŸ“„ Export to CSV", use_container_width=True):
            df = pd.DataFrame(videos_data)
            csv = df.to_csv(index=False)
            st.download_button(
                label="ğŸ’¾ Download CSV",
                data=csv,
                file_name=f"{channel_info.get('title', 'channel')}_analysis.csv",
                mime='text/csv',
                use_container_width=True
            )
        
        # JSON export
        if st.button("ğŸ“‹ Export to JSON", use_container_width=True):
            import json
            json_data = json.dumps(st.session_state.channel_data, indent=2, default=str)
            st.download_button(
                label="ğŸ’¾ Download JSON",
                data=json_data,
                file_name=f"{channel_info.get('title', 'channel')}_analysis.json",
                mime='application/json',
                use_container_width=True
            )
    
    with col2:
        st.subheader("ğŸ“ˆ Analysis Summary")
        
        # Generate summary report
        summary = visualizer.generate_summary_report(channel_info)
        
        st.markdown("### ğŸ“‹ Channel Analysis Summary")
        for key, value in summary.items():
            if isinstance(value, dict):
                st.markdown(f"**{key}:**")
                for sub_key, sub_value in value.items():
                    st.markdown(f"  - {sub_key}: {sub_value}")
            else:
                st.markdown(f"**{key}:** {value}")
        
        # Export summary as text
        summary_text = "\n".join([f"{k}: {v}" for k, v in summary.items()])
        st.download_button(
            label="ğŸ“„ Download Summary Report",
            data=summary_text,
            file_name=f"{channel_info.get('title', 'channel')}_summary.txt",
            mime='text/plain',
            use_container_width=True
        )

if __name__ == "__main__":
    main()
