import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import numpy as np
from datetime import datetime, timedelta
import re
import io
import base64
from collections import Counter
import urllib.parse

from youtube_analyzer import YouTubeAnalyzer
from url_parser import YouTubeURLParser
from data_visualizer import DataVisualizer

# Page configuration
st.set_page_config(
    page_title="ğŸ“Š ìœ íŠœë¸Œ ì±„ë„ ì™„ì „ ë¶„ì„",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Revolutionary UI/UX Design System
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap');
    
    :root {
        --primary: #FF0000;
        --primary-light: #FF6B6B;
        --primary-dark: #CC0000;
        --secondary: #4ECDC4;
        --accent: #FFD93D;
        --bg-primary: #FFFFFF;
        --bg-secondary: #F8FAFC;
        --bg-tertiary: #F1F5F9;
        --text-primary: #1E293B;
        --text-secondary: #64748B;
        --border: #E2E8F0;
        --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
        --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
        --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        --shadow-xl: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
        --shadow-2xl: 0 25px 50px -12px rgba(0, 0, 0, 0.25);
    }
    
    /* Global Styles */
    .main {
        font-family: 'Noto Sans KR', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }
    
    .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    
    /* Glassmorphism Header */
    .main-header {
        text-align: center;
        padding: 4rem 3rem;
        background: rgba(255, 255, 255, 0.1);
        backdrop-filter: blur(20px);
        border: 1px solid rgba(255, 255, 255, 0.2);
        border-radius: 30px;
        margin: 2rem 0 3rem 0;
        position: relative;
        overflow: hidden;
        box-shadow: var(--shadow-2xl);
    }
    
    .main-header::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
        animation: shimmer 3s infinite;
    }
    
    @keyframes shimmer {
        0% { left: -100%; }
        100% { left: 100%; }
    }
    
    .main-header h1 {
        font-size: 3.5rem;
        font-weight: 800;
        margin-bottom: 1rem;
        background: linear-gradient(135deg, #FF0000, #FF6B6B, #FFD93D);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        text-shadow: none;
        letter-spacing: -0.02em;
    }
    
    .main-header p {
        font-size: 1.25rem;
        color: rgba(255, 255, 255, 0.9);
        font-weight: 400;
        letter-spacing: 0.01em;
    }
    
    /* Sidebar Design */
    .sidebar .stSelectbox, .sidebar .stTextInput, .sidebar .stTextArea, .sidebar .stNumberInput {
        margin-bottom: 1rem;
    }
    
    .sidebar .stSelectbox > div > div {
        background: rgba(255, 255, 255, 0.95);
        border: 1px solid rgba(255, 255, 255, 0.3);
        border-radius: 12px;
        backdrop-filter: blur(10px);
    }
    
    .sidebar .stTextInput > div > div > input {
        background: rgba(255, 255, 255, 0.95);
        border: 1px solid rgba(255, 255, 255, 0.3);
        border-radius: 12px;
        backdrop-filter: blur(10px);
        padding: 12px 16px;
        font-weight: 500;
    }
    
    .sidebar .stButton > button {
        width: 100%;
        height: 3.5rem;
        border-radius: 16px;
        font-weight: 700;
        font-size: 1.1rem;
        background: linear-gradient(135deg, #FF0000 0%, #FF6B6B 100%);
        border: none;
        color: white;
        transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
        box-shadow: var(--shadow-lg);
        position: relative;
        overflow: hidden;
    }
    
    .sidebar .stButton > button::before {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
        transition: left 0.5s;
    }
    
    .sidebar .stButton > button:hover {
        transform: translateY(-3px);
        box-shadow: var(--shadow-xl);
    }
    
    .sidebar .stButton > button:hover::before {
        left: 100%;
    }
    
    /* Enhanced Tabs */
    .stTabs [data-baseweb="tab-list"] {
        gap: 12px;
        background: rgba(255, 255, 255, 0.1);
        padding: 8px;
        border-radius: 20px;
        backdrop-filter: blur(10px);
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 3.5rem;
        padding: 12px 24px;
        background: rgba(255, 255, 255, 0.1);
        border-radius: 16px;
        border: 1px solid rgba(255, 255, 255, 0.2);
        font-weight: 600;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        backdrop-filter: blur(10px);
        color: rgba(255, 255, 255, 0.8);
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #FF0000 0%, #FF6B6B 100%);
        color: white !important;
        box-shadow: var(--shadow-lg);
        border: 1px solid rgba(255, 255, 255, 0.3);
        transform: translateY(-2px);
    }
    
    /* Glassmorphism Cards */
    .metric-card, .element-container .stMetric {
        background: rgba(255, 255, 255, 0.15);
        backdrop-filter: blur(20px);
        padding: 2rem;
        border-radius: 20px;
        border: 1px solid rgba(255, 255, 255, 0.2);
        margin: 1rem 0;
        box-shadow: var(--shadow-lg);
        transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
        position: relative;
        overflow: hidden;
    }
    
    .metric-card::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 3px;
        background: linear-gradient(90deg, #FF0000, #FF6B6B, #FFD93D, #4ECDC4);
    }
    
    .metric-card:hover, .element-container .stMetric:hover {
        transform: translateY(-8px) scale(1.02);
        box-shadow: var(--shadow-2xl);
        background: rgba(255, 255, 255, 0.2);
    }
    
    /* Data Tables */
    .stDataFrame {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 20px;
        overflow: hidden;
        box-shadow: var(--shadow-lg);
        backdrop-filter: blur(20px);
    }
    
    .stDataFrame thead tr th {
        background: linear-gradient(135deg, #FF0000 0%, #FF6B6B 100%);
        color: white;
        font-weight: 700;
        padding: 16px;
        border: none;
    }
    
    .stDataFrame tbody tr:nth-child(even) {
        background: rgba(248, 250, 252, 0.5);
    }
    
    .stDataFrame tbody tr:hover {
        background: rgba(255, 107, 107, 0.1);
        transform: scale(1.01);
        transition: all 0.2s ease;
    }
    
    /* Progress and Status */
    .progress-container {
        background: rgba(255, 255, 255, 0.15);
        backdrop-filter: blur(20px);
        padding: 2rem;
        border-radius: 20px;
        margin: 2rem 0;
        border: 1px solid rgba(255, 255, 255, 0.2);
        box-shadow: var(--shadow-lg);
    }
    
    .error-message {
        background: rgba(255, 235, 238, 0.9);
        backdrop-filter: blur(10px);
        color: #c62828;
        padding: 2rem;
        border-radius: 20px;
        border-left: 5px solid #FF4444;
        margin: 2rem 0;
        box-shadow: var(--shadow-lg);
        animation: slideInUp 0.6s cubic-bezier(0.4, 0, 0.2, 1);
    }
    
    .success-message {
        background: rgba(232, 245, 232, 0.9);
        backdrop-filter: blur(10px);
        color: #2e7d32;
        padding: 2rem;
        border-radius: 20px;
        border-left: 5px solid #4CAF50;
        margin: 2rem 0;
        box-shadow: var(--shadow-lg);
        animation: slideInUp 0.6s cubic-bezier(0.4, 0, 0.2, 1);
    }
    
    @keyframes slideInUp {
        from {
            opacity: 0;
            transform: translateY(30px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    /* Enhanced Expanders */
    .streamlit-expanderHeader {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 16px;
        padding: 16px 20px;
        font-weight: 600;
        border: 1px solid rgba(255, 255, 255, 0.2);
        backdrop-filter: blur(10px);
    }
    
    .streamlit-expanderContent {
        background: rgba(255, 255, 255, 0.05);
        border-radius: 0 0 16px 16px;
        border: 1px solid rgba(255, 255, 255, 0.1);
        backdrop-filter: blur(10px);
    }
    
    /* Floating Action Elements */
    .floating-widget {
        position: fixed;
        bottom: 2rem;
        right: 2rem;
        background: linear-gradient(135deg, #FF0000 0%, #FF6B6B 100%);
        color: white;
        padding: 1rem;
        border-radius: 50%;
        box-shadow: var(--shadow-xl);
        cursor: pointer;
        transition: all 0.3s ease;
        z-index: 1000;
    }
    
    .floating-widget:hover {
        transform: scale(1.1) rotate(5deg);
        box-shadow: var(--shadow-2xl);
    }
    
    /* Plotly Chart Container */
    .plotly-graph-div {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 20px;
        padding: 1rem;
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.2);
        margin: 1rem 0;
    }
    
    /* Custom Scrollbar */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    
    ::-webkit-scrollbar-track {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 10px;
    }
    
    ::-webkit-scrollbar-thumb {
        background: linear-gradient(135deg, #FF0000, #FF6B6B);
        border-radius: 10px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: linear-gradient(135deg, #CC0000, #FF4444);
    }
    
    /* Mobile Optimizations */
    @media (max-width: 768px) {
        .main-header h1 {
            font-size: 2.5rem;
        }
        
        .main-header {
            padding: 3rem 2rem;
            margin: 1rem 0 2rem 0;
        }
        
        .metric-card {
            padding: 1.5rem;
        }
        
        .stTabs [data-baseweb="tab"] {
            padding: 10px 16px;
            font-size: 0.9rem;
        }
        
        .floating-widget {
            bottom: 1rem;
            right: 1rem;
        }
    }
    
    /* Loading Animations */
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }
    
    @keyframes bounce {
        0%, 20%, 53%, 80%, 100% { transform: translateY(0); }
        40%, 43% { transform: translateY(-10px); }
        70% { transform: translateY(-5px); }
        90% { transform: translateY(-2px); }
    }
    
    .loading {
        animation: pulse 2s infinite;
    }
    
    .bounce {
        animation: bounce 1s infinite;
    }
    
    /* Dark Mode Support */
    @media (prefers-color-scheme: dark) {
        :root {
            --bg-primary: #0F172A;
            --bg-secondary: #1E293B;
            --bg-tertiary: #334155;
            --text-primary: #F8FAFC;
            --text-secondary: #CBD5E1;
            --border: #475569;
        }
        
        .main {
            background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
        }
    }
</style>
""", unsafe_allow_html=True)

def initialize_session_state():
    """Initialize session state variables"""
    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = None
    if 'channel_data' not in st.session_state:
        st.session_state.channel_data = None
    if 'analysis_complete' not in st.session_state:
        st.session_state.analysis_complete = False
    if 'progress_messages' not in st.session_state:
        st.session_state.progress_messages = []
    if 'error_message' not in st.session_state:
        st.session_state.error_message = None

def show_progress(message):
    """Add progress message to session state"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.progress_messages.append(f"[{timestamp}] {message}")

def display_progress():
    """Display progress messages"""
    if st.session_state.progress_messages:
        st.markdown('<div class="progress-container">', unsafe_allow_html=True)
        st.subheader("ğŸ“ˆ ë¶„ì„ ì§„í–‰ ìƒí™©")
        for message in st.session_state.progress_messages[-10:]:  # Show last 10 messages
            st.text(message)
        st.markdown('</div>', unsafe_allow_html=True)

def display_error(error_msg):
    """Display error message with styling"""
    st.markdown(f'<div class="error-message">âŒ <strong>ì˜¤ë¥˜:</strong> {error_msg}</div>', unsafe_allow_html=True)

def display_success(success_msg):
    """Display success message with styling"""
    st.markdown(f'<div class="success-message">âœ… <strong>ì„±ê³µ:</strong> {success_msg}</div>', unsafe_allow_html=True)

def main():
    initialize_session_state()
    st.title("ìœ íŠœë¸Œ ë°ì´í„° ëŒ€ì‹œë³´ë“œ")
    st.write("ì•±ì´ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # Main header with enhanced features
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“Š ìœ íŠœë¸Œ ì±„ë„ ì™„ì „ ë¶„ì„</h1>
        <p>AI ê¸°ë°˜ ë°ì´í„° ë¶„ì„ Â· ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ì˜ˆì¸¡ Â· ì„±ê³¼ ìµœì í™”</p>
        <div style="margin-top: 2rem; display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap;">
            <span style="background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 20px; font-size: 0.9rem;">âœ¨ ì‹¤ì‹œê°„ ë¶„ì„</span>
            <span style="background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 20px; font-size: 0.9rem;">ğŸ¯ ì„±ê³µ íŒ¨í„´ AI</span>
            <span style="background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 20px; font-size: 0.9rem;">ğŸ“ˆ íŠ¸ë Œë“œ ì˜ˆì¸¡</span>
            <span style="background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 20px; font-size: 0.9rem;">ğŸ”® ìˆ˜ìµ ì˜ˆìƒ</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Add floating help button
    st.markdown("""
    <div class="floating-widget" title="ë„ì›€ë§">
        <div style="font-size: 1.5rem;">â“</div>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar for inputs
    with st.sidebar:
        st.header("ğŸ”§ ì„¤ì •")
        
        # API Key input
        st.subheader("ğŸ”‘ YouTube Data API í‚¤")
        api_key = st.text_input(
            "YouTube Data API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            type="password",
            help="Google Cloud Consoleì—ì„œ YouTube Data API v3 í‚¤ë¥¼ ë°œê¸‰ë°›ìœ¼ì„¸ìš”"
        )
        
        if not api_key:
            st.warning("âš ï¸ ì§„í–‰í•˜ë ¤ë©´ YouTube Data API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            st.markdown("""
            **API í‚¤ ë°œê¸‰ ë°©ë²•:**
            1. [Google Cloud Console](https://console.cloud.google.com/) ì ‘ì†
            2. ìƒˆ í”„ë¡œì íŠ¸ ìƒì„± ë˜ëŠ” ê¸°ì¡´ í”„ë¡œì íŠ¸ ì„ íƒ
            3. YouTube Data API v3 í™œì„±í™”
            4. ì‚¬ìš©ì ì¸ì¦ ì •ë³´ ìƒì„± (API í‚¤)
            5. ìœ„ì— í‚¤ë¥¼ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸°
            """)
        
        # Channel input
        st.subheader("ğŸ“º ì±„ë„ ì •ë³´")
        channel_input = st.text_input(
            "ì±„ë„ëª… ë˜ëŠ” URL",
            placeholder="ì˜ˆ: ì¹™ì¹™í’‰í’‰ ë˜ëŠ” https://www.youtube.com/@ì¹™ì¹™í’‰í’‰",
            help="ì±„ë„ëª…, @í•¸ë“¤, ë˜ëŠ” ëª¨ë“  í˜•íƒœì˜ ìœ íŠœë¸Œ ì±„ë„ URLì„ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        # Advanced Analysis options
        st.subheader("âš™ï¸ ê³ ê¸‰ ë¶„ì„ ì˜µì…˜")
        
        # Basic options
        with st.expander("ğŸ“Š ê¸°ë³¸ ì„¤ì •", expanded=True):
            max_videos = st.selectbox(
                "ë¶„ì„í•  ìµœëŒ€ ì˜ìƒ ìˆ˜",
                [10, 20, 50, 100, 200, 500, 1000, 2000, 5000],
                index=4,
                help="ë” ë§ì€ ì˜ìƒ = ë” ì •í™•í•œ ë¶„ì„ (ì²˜ë¦¬ ì‹œê°„ ì¦ê°€)"
            )
            
            col1, col2 = st.columns(2)
            with col1:
                include_shorts = st.checkbox("ì‡¼ì¸  í¬í•¨", value=True)
            with col2:
                include_long_form = st.checkbox("ë¡±í¼ í¬í•¨", value=True)
        
        # Date range filter
        with st.expander("ğŸ“… ë‚ ì§œ í•„í„°"):
            use_date_filter = st.checkbox("ë‚ ì§œ ë²”ìœ„ ì„¤ì •")
            if use_date_filter:
                date_from = st.date_input("ì‹œì‘ ë‚ ì§œ", value=datetime.now() - timedelta(days=365))
                date_to = st.date_input("ì¢…ë£Œ ë‚ ì§œ", value=datetime.now())
        
        # Performance filters
        with st.expander("ğŸ¯ ì„±ê³¼ í•„í„°"):
            min_views = st.number_input("ìµœì†Œ ì¡°íšŒìˆ˜", min_value=0, value=0)
            min_likes = st.number_input("ìµœì†Œ ì¢‹ì•„ìš” ìˆ˜", min_value=0, value=0)
            
        # Analysis depth
        with st.expander("ğŸ” ë¶„ì„ ê¹Šì´"):
            analyze_thumbnails = st.checkbox("ì¸ë„¤ì¼ ìƒ‰ìƒ ë¶„ì„", value=True)
            analyze_sentiment = st.checkbox("ì œëª© ê°ì • ë¶„ì„", value=True)
            predict_trends = st.checkbox("íŠ¸ë Œë“œ ì˜ˆì¸¡", value=True)
            competitor_analysis = st.checkbox("ê²½ìŸì ë¶„ì„ (ë² íƒ€)", value=False)
        
        # Export options
        with st.expander("ğŸ’¾ ë‚´ë³´ë‚´ê¸° ì„¤ì •"):
            export_format = st.selectbox("ë‚´ë³´ë‚´ê¸° í˜•ì‹", ["Excel", "CSV", "JSON"])
            include_charts = st.checkbox("ì°¨íŠ¸ ì´ë¯¸ì§€ í¬í•¨", value=True)
        
        st.divider()
        
        # Analysis button
        analyze_button = st.button(
            "ğŸš€ ë¶„ì„ ì‹œì‘",
            type="primary",
            disabled=not (api_key and channel_input),
            use_container_width=True
        )
    
    # Main content area
    if analyze_button and api_key and channel_input:
        st.session_state.progress_messages = []
        st.session_state.error_message = None
        st.session_state.analysis_complete = False
        
        # Initialize analyzer
        show_progress("ìœ íŠœë¸Œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
        st.session_state.analyzer = YouTubeAnalyzer(api_key)
        
        # Parse channel input
        show_progress("ì±„ë„ ì •ë³´ íŒŒì‹± ì¤‘...")
        parser = YouTubeURLParser()
        
        try:
            channel_info = parser.parse_channel_input(channel_input)
            show_progress(f"ì±„ë„ íŒŒì‹± ì™„ë£Œ: {channel_info}")
            
            # Get channel data
            show_progress("ì±„ë„ ì„¸ë¶€ ì •ë³´ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            channel_data = st.session_state.analyzer.get_channel_info(channel_info)
            
            if not channel_data:
                display_error("ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì±„ë„ëª…ì´ë‚˜ URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return
            
            show_progress(f"ì±„ë„ ë°œê²¬: {channel_data.get('title', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
            
            # Create progress container
            progress_container = st.container()
            with progress_container:
                display_progress()
            
            # Collect video data
            show_progress("ì˜ìƒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # Create a progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def progress_callback(current, total, message):
                progress = min(current / total, 1.0) if total > 0 else 0
                progress_bar.progress(progress)
                status_text.text(f"{message} ({current}/{total})")
                show_progress(f"{message} ({current}/{total})")
            
            videos_data = st.session_state.analyzer.collect_all_videos(
                channel_data['id'],
                max_results=max_videos,
                include_shorts=include_shorts,
                include_long_form=include_long_form,
                progress_callback=progress_callback
            )
            
            if not videos_data:
                display_error("ì´ ì±„ë„ì—ì„œ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            progress_bar.progress(1.0)
            status_text.text(f"ë¶„ì„ ì™„ë£Œ! {len(videos_data)}ê°œ ì˜ìƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
            
            # Store data in session state
            st.session_state.channel_data = {
                'channel_info': channel_data,
                'videos': videos_data
            }
            st.session_state.analysis_complete = True
            
            display_success(f"{channel_data.get('title', 'ì•Œ ìˆ˜ ì—†ëŠ”')} ì±„ë„ì˜ {len(videos_data)}ê°œ ì˜ìƒ ë¶„ì„ì„ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            display_error(f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {str(e)}")
            return
    
    # Display results if analysis is complete
    if st.session_state.analysis_complete and st.session_state.channel_data:
        display_analysis_results()

def display_analysis_results():
    """Display comprehensive analysis results"""
    channel_info = st.session_state.channel_data['channel_info']
    videos_data = st.session_state.channel_data['videos']
    
    # Create visualizer
    visualizer = DataVisualizer(videos_data)
    
    st.header(f"ğŸ“Š {channel_info.get('title', 'ì•Œ ìˆ˜ ì—†ëŠ” ì±„ë„')} ë¶„ì„ ê²°ê³¼")
    
    # Channel overview with enhanced metrics
    col1, col2, col3, col4 = st.columns(4)
    
    total_videos = len(videos_data)
    total_views = sum(video.get('view_count', 0) for video in videos_data)
    total_likes = sum(video.get('like_count', 0) for video in videos_data)
    total_comments = sum(video.get('comment_count', 0) for video in videos_data)
    avg_views = total_views / total_videos if total_videos > 0 else 0
    
    shorts_count = sum(1 for video in videos_data if video.get('is_short', False))
    long_form_count = total_videos - shorts_count
    
    # Calculate engagement metrics
    total_engagement = total_likes + total_comments
    avg_engagement_rate = (total_engagement / total_views * 100) if total_views > 0 else 0
    
    with col1:
        st.metric("ì´ ì˜ìƒ ìˆ˜", f"{total_videos:,}")
        st.metric("ì‡¼ì¸ ", f"{shorts_count:,}")
    
    with col2:
        st.metric("ì´ ì¡°íšŒìˆ˜", f"{total_views:,}")
        st.metric("í‰ê·  ì¡°íšŒìˆ˜", f"{avg_views:,.0f}")
    
    with col3:
        st.metric("ì´ ì¢‹ì•„ìš”", f"{total_likes:,}")
        st.metric("ë¡±í¼", f"{long_form_count:,}")
    
    with col4:
        subscriber_count = channel_info.get('subscriber_count', 0)
        video_count = channel_info.get('video_count', 0)
        st.metric("êµ¬ë…ì ìˆ˜", f"{subscriber_count:,}")
        st.metric("ì±„ë„ ì´ ì˜ìƒ", f"{video_count:,}")
    
    # Additional metrics row
    col5, col6, col7, col8 = st.columns(4)
    
    with col5:
        st.metric("ì´ ëŒ“ê¸€", f"{total_comments:,}")
    
    with col6:
        st.metric("í‰ê·  ì°¸ì—¬ìœ¨", f"{avg_engagement_rate:.2f}%")
    
    with col7:
        # Calculate average upload frequency
        if total_videos > 1:
            date_range = (max(video['published_at'] for video in videos_data) - 
                         min(video['published_at'] for video in videos_data)).days
            upload_frequency = date_range / total_videos if date_range > 0 else 0
            st.metric("í‰ê·  ì—…ë¡œë“œ ê°„ê²©", f"{upload_frequency:.1f}ì¼")
        else:
            st.metric("í‰ê·  ì—…ë¡œë“œ ê°„ê²©", "N/A")
    
    with col8:
        # Most successful video
        if videos_data:
            best_video = max(videos_data, key=lambda x: x.get('view_count', 0))
            st.metric("ìµœê³  ì¡°íšŒìˆ˜", f"{best_video.get('view_count', 0):,}")
    
    # Create enhanced analysis tabs with new features
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9, tab10 = st.tabs([
        "ğŸ“ˆ ì„±ê³¼ ê°œìš”",
        "ğŸ“… ì—…ë¡œë“œ íŒ¨í„´", 
        "ğŸ”¥ ì¸ê¸° ì˜ìƒ",
        "ğŸ”¤ í‚¤ì›Œë“œ ë¶„ì„",
        "ğŸ¯ ì„±ê³µ íŒ¨í„´",
        "ğŸ’° ìˆ˜ìµ ë¶„ì„",
        "ğŸ¤– AI ì¶”ì²œ",
        "ğŸ“Š ìƒì„¸ ë°ì´í„°",
        "ğŸ”® íŠ¸ë Œë“œ ì˜ˆì¸¡",
        "ğŸ“‹ ë‚´ë³´ë‚´ê¸° & ë¦¬í¬íŠ¸"
    ])
    
    with tab1:
        display_performance_overview(visualizer)
    
    with tab2:
        display_upload_patterns(visualizer)
    
    with tab3:
        display_top_videos(visualizer)
    
    with tab4:
        display_keywords_analysis(visualizer)
    
    with tab5:
        display_success_patterns(visualizer)
    
    with tab6:
        display_revenue_analysis(visualizer, channel_info)
    
    with tab7:
        display_ai_recommendations(visualizer, channel_info)
    
    with tab8:
        display_detailed_data()
    
    with tab9:
        display_trend_prediction(visualizer)
    
    with tab10:
        display_export_options(visualizer)

def display_performance_overview(visualizer):
    """Display performance overview charts"""
    st.subheader("ğŸ“ˆ ì„±ê³¼ ê°œìš”")
    
    # Views distribution
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ì¡°íšŒìˆ˜ ë¶„í¬")
        fig = visualizer.create_views_distribution()
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("ì°¸ì—¬ìœ¨ ë¶„ì„")
        fig = visualizer.create_engagement_chart()
        st.plotly_chart(fig, use_container_width=True)
    
    # Performance comparison: Shorts vs Long-form
    st.subheader("ğŸ“Š ì‡¼ì¸  vs ë¡±í¼ ì„±ê³¼ ë¹„êµ")
    fig = visualizer.create_shorts_vs_longform_comparison()
    st.plotly_chart(fig, use_container_width=True)
    
    # Duration vs Views correlation
    st.subheader("â±ï¸ ì˜ìƒ ê¸¸ì´ì™€ ì¡°íšŒìˆ˜ ìƒê´€ê´€ê³„")
    fig = visualizer.create_duration_views_correlation()
    st.plotly_chart(fig, use_container_width=True)

def display_upload_patterns(visualizer):
    """Display upload pattern analysis"""
    st.subheader("ğŸ“… ì—…ë¡œë“œ íŒ¨í„´ ë¶„ì„")
    
    # Monthly upload trends
    st.subheader("ğŸ“Š ì›”ë³„ ì—…ë¡œë“œ íŠ¸ë Œë“œ")
    fig = visualizer.create_monthly_trends()
    st.plotly_chart(fig, use_container_width=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“… ìš”ì¼ë³„ ì—…ë¡œë“œ íŒ¨í„´")
        fig = visualizer.create_weekday_analysis()
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("ğŸ• ì‹œê°„ëŒ€ë³„ ì—…ë¡œë“œ íŒ¨í„´")
        fig = visualizer.create_hourly_analysis()
        st.plotly_chart(fig, use_container_width=True)
    
    # Upload consistency analysis
    st.subheader("ğŸ“ˆ ì—…ë¡œë“œ ì¼ê´€ì„± ë¶„ì„")
    consistency_data = visualizer.analyze_upload_consistency()
    
    # Display consistency data in a more user-friendly format
    if 'error' not in consistency_data:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ì´ ì˜ìƒ ìˆ˜", f"{consistency_data['total_videos']:,}")
            st.metric("í™œë™ ê¸°ê°„", f"{consistency_data['date_range']['days_active']}ì¼")
        
        with col2:
            st.metric("í‰ê·  ì—…ë¡œë“œ ê°„ê²©", f"{consistency_data['upload_frequency']['average_gap_days']:.1f}ì¼")
            st.metric("ì£¼ë‹¹ ì—…ë¡œë“œ ìˆ˜", f"{consistency_data['upload_patterns']['uploads_per_week']:.1f}ê°œ")
        
        with col3:
            st.metric("ê°€ì¥ í™œë°œí•œ ìš”ì¼", consistency_data['upload_patterns']['most_active_day'])
            st.metric("ì£¼ìš” ì—…ë¡œë“œ ì‹œê°„", f"{consistency_data['upload_patterns']['most_active_hour']}ì‹œ")
    else:
        st.error("ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

def display_top_videos(visualizer):
    """Display top performing videos"""
    st.subheader("ğŸ”¥ ì¸ê¸° ì˜ìƒ ë¶„ì„")
    
    # Top videos by different metrics
    metric_type = st.selectbox(
        "ìƒìœ„ ì˜ìƒ ì •ë ¬ ê¸°ì¤€ ì„ íƒ",
        ["view_count", "like_count", "comment_count", "engagement_rate"],
        format_func=lambda x: {
            "view_count": "ğŸ‘ï¸ ì¡°íšŒìˆ˜",
            "like_count": "ğŸ‘ ì¢‹ì•„ìš”", 
            "comment_count": "ğŸ’¬ ëŒ“ê¸€ìˆ˜",
            "engagement_rate": "ğŸ“Š ì°¸ì—¬ìœ¨"
        }[x]
    )
    
    # Number of top videos to display
    top_count = st.slider("í‘œì‹œí•  ìƒìœ„ ì˜ìƒ ìˆ˜", min_value=5, max_value=50, value=20)
    
    top_videos = visualizer.get_top_videos(metric=metric_type, count=top_count)
    
    # Display top videos table
    if top_videos:
        df = pd.DataFrame(top_videos)
        
        # Format the dataframe for display
        display_df = df[['title', 'published_at', 'view_count', 'like_count', 'comment_count', 'duration_formatted', 'is_short']].copy()
        display_df.columns = ['ì œëª©', 'ì—…ë¡œë“œì¼', 'ì¡°íšŒìˆ˜', 'ì¢‹ì•„ìš”', 'ëŒ“ê¸€ìˆ˜', 'ê¸¸ì´', 'ìœ í˜•']
        display_df['ìœ í˜•'] = ['ì‡¼ì¸ ' if x else 'ë¡±í¼' for x in display_df['ìœ í˜•']]
        
        # Format numbers with commas
        for col in ['ì¡°íšŒìˆ˜', 'ì¢‹ì•„ìš”', 'ëŒ“ê¸€ìˆ˜']:
            if col in display_df.columns:
                display_df[col] = [f"{x:,}" if isinstance(x, (int, float)) else x for x in display_df[col]]
        
        st.dataframe(
            display_df,
            use_container_width=True,
            hide_index=True
        )
        
        # Top video performance chart
        metric_name = {
            "view_count": "ì¡°íšŒìˆ˜",
            "like_count": "ì¢‹ì•„ìš”",
            "comment_count": "ëŒ“ê¸€ìˆ˜",
            "engagement_rate": "ì°¸ì—¬ìœ¨"
        }[metric_type]
        
        st.subheader(f"ğŸ“Š {metric_name} ê¸°ì¤€ ìƒìœ„ 10ê°œ ì˜ìƒ")
        fig = visualizer.create_top_videos_chart(metric=metric_type, count=10)
        st.plotly_chart(fig, use_container_width=True)
        
        # Performance insights
        if len(top_videos) >= 3:
            st.subheader("ğŸ’¡ ì¸ê¸° ì˜ìƒ ì¸ì‚¬ì´íŠ¸")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ìƒìœ„ 3ê°œ ì˜ìƒ í‰ê·  ì„±ê³¼:**")
                top_3 = top_videos[:3]
                avg_views = sum(v['view_count'] for v in top_3) / 3
                avg_likes = sum(v['like_count'] for v in top_3) / 3
                avg_comments = sum(v['comment_count'] for v in top_3) / 3
                
                st.metric("í‰ê·  ì¡°íšŒìˆ˜", f"{avg_views:,.0f}")
                st.metric("í‰ê·  ì¢‹ì•„ìš”", f"{avg_likes:,.0f}")
                st.metric("í‰ê·  ëŒ“ê¸€", f"{avg_comments:,.0f}")
            
            with col2:
                st.write("**ì¸ê¸° ì˜ìƒ ìœ í˜• ë¶„í¬:**")
                shorts_in_top = sum(1 for v in top_videos[:10] if v.get('is_short', False))
                longform_in_top = 10 - shorts_in_top
                
                st.metric("ìƒìœ„ 10ê°œ ì¤‘ ì‡¼ì¸ ", f"{shorts_in_top}ê°œ")
                st.metric("ìƒìœ„ 10ê°œ ì¤‘ ë¡±í¼", f"{longform_in_top}ê°œ")
    else:
        st.info("í‘œì‹œí•  ì˜ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

def display_success_patterns(visualizer):
    """Display analysis of successful video patterns"""
    st.subheader("ğŸ¯ ì„±ê³µ íŒ¨í„´ ë¶„ì„")
    
    # Get successful patterns
    patterns = visualizer.analyze_successful_patterns()
    
    if patterns and 'top_keywords' in patterns:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ”¥ ê³ ì„±ê³¼ í‚¤ì›Œë“œ")
            if patterns.get('top_keywords'):
                keywords_data = []
                for keyword, data in list(patterns['top_keywords'].items())[:10]:
                    keywords_data.append({
                        'í‚¤ì›Œë“œ': keyword,
                        'ì˜ìƒìˆ˜': data['count'],
                        'í‰ê·  ì¡°íšŒìˆ˜': f"{data['avg_views']:,.0f}"
                    })
                
                if keywords_data:
                    st.dataframe(pd.DataFrame(keywords_data), use_container_width=True, hide_index=True)
                else:
                    st.info("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ë¶„ì„í•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        with col2:
            st.subheader("ğŸ“ˆ ìµœì  ì—…ë¡œë“œ ì‹œê°„")
            if patterns.get('best_times'):
                times_data = []
                for time_info in patterns['best_times'][:5]:
                    # Handle both dict and other formats safely
                    if isinstance(time_info, dict):
                        hour = time_info.get('hour', 0)
                        count = time_info.get('count', 0)
                        avg_views = time_info.get('avg_views', 0)
                        times_data.append({
                            'ì‹œê°„ëŒ€': f"{hour}ì‹œ",
                            'ì˜ìƒìˆ˜': count,
                            'í‰ê·  ì¡°íšŒìˆ˜': f"{avg_views:,.0f}"
                        })
                
                if times_data:
                    st.dataframe(pd.DataFrame(times_data), use_container_width=True, hide_index=True)
                else:
                    st.info("ì‹œê°„ëŒ€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ì—…ë¡œë“œ ì‹œê°„ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # Best performing video length analysis
    st.subheader("â±ï¸ ìµœì  ì˜ìƒ ê¸¸ì´ ë¶„ì„")
    videos_data = visualizer.videos_data
    if videos_data:
        # Group by duration ranges
        duration_ranges = []
        for video in videos_data:
            duration = video.get('duration_seconds', 0)
            if duration <= 60:
                range_name = "ì‡¼ì¸  (â‰¤60ì´ˆ)"
            elif duration <= 300:
                range_name = "ë‹¨í¸ (1-5ë¶„)"
            elif duration <= 600:
                range_name = "ì¤‘í¸ (5-10ë¶„)"
            elif duration <= 1200:
                range_name = "ì¥í¸ (10-20ë¶„)"
            else:
                range_name = "ì¥ì‹œê°„ (>20ë¶„)"
            
            duration_ranges.append({
                'range': range_name,
                'views': video.get('view_count', 0),
                'likes': video.get('like_count', 0),
                'comments': video.get('comment_count', 0)
            })
        
        if duration_ranges:
            df_duration = pd.DataFrame(duration_ranges)
            duration_summary = df_duration.groupby('range').agg({
                'views': ['count', 'mean', 'median'],
                'likes': 'mean',
                'comments': 'mean'
            }).round(0)
            
            duration_summary.columns = ['ì˜ìƒìˆ˜', 'í‰ê· ì¡°íšŒìˆ˜', 'ì¤‘ê°„ì¡°íšŒìˆ˜', 'í‰ê· ì¢‹ì•„ìš”', 'í‰ê· ëŒ“ê¸€']
            duration_summary = duration_summary.reset_index()
            duration_summary.columns = ['ê¸¸ì´ë²”ìœ„', 'ì˜ìƒìˆ˜', 'í‰ê· ì¡°íšŒìˆ˜', 'ì¤‘ê°„ì¡°íšŒìˆ˜', 'í‰ê· ì¢‹ì•„ìš”', 'í‰ê· ëŒ“ê¸€']
            
            # Format numbers
            for col in ['ì˜ìƒìˆ˜', 'í‰ê· ì¡°íšŒìˆ˜', 'ì¤‘ê°„ì¡°íšŒìˆ˜', 'í‰ê· ì¢‹ì•„ìš”', 'í‰ê· ëŒ“ê¸€']:
                duration_summary[col] = duration_summary[col].apply(lambda x: f"{int(x):,}")
            
            st.dataframe(duration_summary, use_container_width=True, hide_index=True)
    
    # Title pattern analysis
    st.subheader("ğŸ“ ì œëª© íŒ¨í„´ ë¶„ì„")
    if videos_data:
        # Analyze title characteristics of top performing videos
        top_videos = sorted(videos_data, key=lambda x: x.get('view_count', 0), reverse=True)[:20]
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            avg_title_length = sum(len(v.get('title', '')) for v in top_videos) / len(top_videos)
            st.metric("ìƒìœ„ ì˜ìƒ í‰ê·  ì œëª© ê¸¸ì´", f"{avg_title_length:.0f}ì")
        
        with col2:
            question_titles = sum(1 for v in top_videos if '?' in v.get('title', ''))
            st.metric("ë¬¼ìŒí‘œ í¬í•¨ ì œëª©", f"{question_titles}ê°œ")
        
        with col3:
            exclamation_titles = sum(1 for v in top_videos if '!' in v.get('title', ''))
            st.metric("ëŠë‚Œí‘œ í¬í•¨ ì œëª©", f"{exclamation_titles}ê°œ")

def display_trend_prediction(visualizer):
    """Display trend prediction and future insights"""
    st.subheader("ğŸ”® íŠ¸ë Œë“œ ì˜ˆì¸¡ ë° ì¸ì‚¬ì´íŠ¸")
    
    videos_data = visualizer.videos_data
    if not videos_data or len(videos_data) < 10:
        st.warning("íŠ¸ë Œë“œ ì˜ˆì¸¡ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 10ê°œ ì´ìƒì˜ ì˜ìƒì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    # Growth trend analysis
    st.subheader("ğŸ“ˆ ì„±ì¥ íŠ¸ë Œë“œ ë¶„ì„")
    
    # Sort videos by date
    sorted_videos = sorted(videos_data, key=lambda x: x.get('published_at'))
    
    # Calculate monthly growth
    monthly_data = {}
    for video in sorted_videos:
        month_key = video['published_at'].strftime('%Y-%m')
        if month_key not in monthly_data:
            monthly_data[month_key] = {
                'count': 0,
                'total_views': 0,
                'total_likes': 0,
                'total_comments': 0
            }
        monthly_data[month_key]['count'] += 1
        monthly_data[month_key]['total_views'] += video.get('view_count', 0)
        monthly_data[month_key]['total_likes'] += video.get('like_count', 0)
        monthly_data[month_key]['total_comments'] += video.get('comment_count', 0)
    
    if len(monthly_data) >= 3:
        months = sorted(monthly_data.keys())
        recent_months = months[-3:]
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            recent_avg_views = sum(monthly_data[m]['total_views'] for m in recent_months) / len(recent_months)
            older_months = months[:-3] if len(months) > 3 else months[:3]
            older_avg_views = sum(monthly_data[m]['total_views'] for m in older_months) / len(older_months) if older_months else recent_avg_views
            
            growth_rate = ((recent_avg_views - older_avg_views) / older_avg_views * 100) if older_avg_views > 0 else 0
            st.metric("ìµœê·¼ 3ê°œì›” ì„±ì¥ë¥ ", f"{growth_rate:+.1f}%")
        
        with col2:
            recent_upload_count = sum(monthly_data[m]['count'] for m in recent_months)
            st.metric("ìµœê·¼ 3ê°œì›” ì—…ë¡œë“œ", f"{recent_upload_count}ê°œ")
        
        with col3:
            if len(recent_months) >= 2:
                last_month_views = monthly_data[recent_months[-1]]['total_views']
                prev_month_views = monthly_data[recent_months[-2]]['total_views']
                month_growth = ((last_month_views - prev_month_views) / prev_month_views * 100) if prev_month_views > 0 else 0
                st.metric("ì „ì›” ëŒ€ë¹„ ì„±ì¥ë¥ ", f"{month_growth:+.1f}%")
    
    # Content recommendations
    st.subheader("ğŸ’¡ ì½˜í…ì¸  ì¶”ì²œ")
    
    # Analyze successful content patterns
    top_performing = sorted(videos_data, key=lambda x: x.get('view_count', 0), reverse=True)[:10]
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ì„±ê³µ ìš”ì¸ ë¶„ì„:**")
        
        # Most successful video type
        shorts_performance = [v for v in top_performing if v.get('is_short', False)]
        longform_performance = [v for v in top_performing if not v.get('is_short', False)]
        
        if len(shorts_performance) > len(longform_performance):
            st.info("ğŸ¯ ì‡¼ì¸  ì½˜í…ì¸ ê°€ ë” ë†’ì€ ì„±ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤")
        else:
            st.info("ğŸ¯ ë¡±í¼ ì½˜í…ì¸ ê°€ ë” ë†’ì€ ì„±ê³¼ë¥¼ ë³´ì…ë‹ˆë‹¤")
        
        # Best upload day
        day_performance = {}
        for video in top_performing:
            day = video['published_at'].strftime('%A')
            if day not in day_performance:
                day_performance[day] = 0
            day_performance[day] += 1
        
        if day_performance:
            best_day = max(day_performance.keys(), key=lambda x: day_performance[x])
            day_names = {
                'Monday': 'ì›”ìš”ì¼', 'Tuesday': 'í™”ìš”ì¼', 'Wednesday': 'ìˆ˜ìš”ì¼',
                'Thursday': 'ëª©ìš”ì¼', 'Friday': 'ê¸ˆìš”ì¼', 'Saturday': 'í† ìš”ì¼', 'Sunday': 'ì¼ìš”ì¼'
            }
            st.info(f"ğŸ“… {day_names.get(best_day, best_day)}ì— ì—…ë¡œë“œí•œ ì˜ìƒì˜ ì„±ê³¼ê°€ ì¢‹ìŠµë‹ˆë‹¤")
    
    with col2:
        st.write("**ê°œì„  ì œì•ˆ:**")
        
        # Upload consistency
        upload_gaps = []
        for i in range(1, len(sorted_videos)):
            gap = (sorted_videos[i]['published_at'] - sorted_videos[i-1]['published_at']).days
            upload_gaps.append(gap)
        
        if upload_gaps:
            avg_gap = sum(upload_gaps) / len(upload_gaps)
            if avg_gap > 7:
                st.warning("âš¡ ì—…ë¡œë“œ ì£¼ê¸°ë¥¼ ë” ì§§ê²Œ í•˜ë©´ ì„±ì¥ì— ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            elif avg_gap < 1:
                st.warning("â° ë„ˆë¬´ ìì£¼ ì—…ë¡œë“œí•˜ë©´ í’ˆì§ˆì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            else:
                st.success("âœ… ì ì ˆí•œ ì—…ë¡œë“œ ì£¼ê¸°ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤")
        
        # Engagement rate analysis
        recent_videos = sorted_videos[-10:] if len(sorted_videos) >= 10 else sorted_videos
        avg_engagement = sum(v.get('engagement_rate', 0) for v in recent_videos) / len(recent_videos)
        
        if avg_engagement < 2:
            st.warning("ğŸ’¬ ì‹œì²­ì ì°¸ì—¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ëŒ“ê¸€ì„ ìœ ë„í•˜ëŠ” ì§ˆë¬¸ì´ë‚˜ ìƒí˜¸ì‘ìš©ì„ ëŠ˜ë ¤ë³´ì„¸ìš”")
        elif avg_engagement > 5:
            st.success("ğŸ”¥ ë†’ì€ ì°¸ì—¬ë„ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤!")
        else:
            st.info("ğŸ“Š í‰ê· ì ì¸ ì°¸ì—¬ë„ì…ë‹ˆë‹¤. ë” ë§ì€ ìƒí˜¸ì‘ìš©ì„ ì‹œë„í•´ë³´ì„¸ìš”")

def display_revenue_analysis(visualizer, channel_info):
    """Display revenue estimation and monetization analysis"""
    st.subheader("ğŸ’° ìˆ˜ìµ ë¶„ì„ ë° ì˜ˆìƒ")
    
    videos_data = visualizer.videos_data
    if not videos_data:
        st.warning("ìˆ˜ìµ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # Calculate revenue estimates
    total_views = sum(video.get('view_count', 0) for video in videos_data)
    subscriber_count = channel_info.get('subscriber_count', 0)
    
    # Revenue calculation (rough estimates based on industry averages)
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        # Ad revenue estimation (RPM: Revenue per Mille)
        estimated_rpm = 1.5  # $1-3 per 1000 views average
        ad_revenue = (total_views / 1000) * estimated_rpm
        st.metric("ì˜ˆìƒ ê´‘ê³  ìˆ˜ìµ", f"${ad_revenue:,.0f}")
    
    with col2:
        # Sponsorship potential
        if subscriber_count > 10000:
            sponsor_rate = subscriber_count * 0.01  # $0.01 per subscriber
            st.metric("ìŠ¤í°ì„œì‹­ ì ì¬ê°€ì¹˜", f"${sponsor_rate:,.0f}")
        else:
            st.metric("ìŠ¤í°ì„œì‹­ ì ì¬ê°€ì¹˜", "N/A")
    
    with col3:
        # Monthly earning potential
        from datetime import timezone
        now = datetime.now(timezone.utc)
        recent_videos = []
        for v in videos_data:
            pub_date = v['published_at']
            if hasattr(pub_date, 'tz_localize'):
                pub_date = pub_date.tz_localize('UTC') if pub_date.tz is None else pub_date
            elif not hasattr(pub_date, 'tzinfo') or pub_date.tzinfo is None:
                pub_date = pub_date.replace(tzinfo=timezone.utc)
            
            if (now - pub_date).days <= 30:
                recent_videos.append(v)
        monthly_views = sum(v.get('view_count', 0) for v in recent_videos)
        monthly_revenue = (monthly_views / 1000) * estimated_rpm
        st.metric("ì›” ì˜ˆìƒ ìˆ˜ìµ", f"${monthly_revenue:,.0f}")
    
    with col4:
        # Growth potential
        if len(videos_data) >= 10:
            recent_avg = sum(v.get('view_count', 0) for v in videos_data[-5:]) / 5
            older_avg = sum(v.get('view_count', 0) for v in videos_data[-10:-5]) / 5
            growth = ((recent_avg - older_avg) / older_avg * 100) if older_avg > 0 else 0
            st.metric("ì„±ì¥ë¥ ", f"{growth:+.1f}%")
    
    # Revenue breakdown chart
    st.subheader("ğŸ“Š ìˆ˜ìµì›ë³„ ë¶„ì„")
    
    # Create revenue sources data
    revenue_sources = {
        'ê´‘ê³  ìˆ˜ìµ': ad_revenue,
        'ë©¤ë²„ì‹­': ad_revenue * 0.3,  # Estimated membership revenue
        'ìŠˆí¼ì±—': ad_revenue * 0.1,   # Estimated super chat
        'ë¨¸ì²œë‹¤ì´ì¦ˆ': ad_revenue * 0.2  # Estimated merchandise
    }
    
    import plotly.express as px
    
    fig = px.pie(
        values=list(revenue_sources.values()),
        names=list(revenue_sources.keys()),
        title="ì˜ˆìƒ ìˆ˜ìµì› ë¶„í¬",
        color_discrete_sequence=['#FF0000', '#FF6B6B', '#FFD93D', '#4ECDC4']
    )
    
    fig.update_layout(
        font=dict(family="Noto Sans KR, sans-serif"),
        title_font=dict(size=16, family="Noto Sans KR, sans-serif")
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Revenue optimization tips
    st.subheader("ğŸ’¡ ìˆ˜ìµ ìµœì í™” íŒ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ì¦‰ì‹œ ì ìš© ê°€ëŠ¥:**")
        tips = []
        
        if subscriber_count < 1000:
            tips.append("â€¢ 1,000ëª… êµ¬ë…ì ë‹¬ì„±ìœ¼ë¡œ ìˆ˜ìµí™” ì‹œì‘")
        if len([v for v in videos_data if v.get('duration_seconds', 0) > 480]) < 5:
            tips.append("â€¢ 8ë¶„ ì´ìƒ ì˜ìƒìœ¼ë¡œ ì¤‘ê°„ ê´‘ê³  ì‚½ì…")
        if monthly_views < 10000:
            tips.append("â€¢ ì—…ë¡œë“œ ì£¼ê¸° ë‹¨ì¶•ìœ¼ë¡œ ë…¸ì¶œ ì¦ëŒ€")
        
        if not tips:
            tips = ["â€¢ í˜„ì¬ ìˆ˜ìµí™” ì¡°ê±´ì„ ì˜ ë§Œì¡±í•˜ê³  ìˆìŠµë‹ˆë‹¤!"]
        
        for tip in tips:
            st.write(tip)
    
    with col2:
        st.write("**ì¥ê¸° ì „ëµ:**")
        long_term_tips = [
            "â€¢ ë¸Œëœë“œ í˜‘ì°¬ ë° ì œí’ˆ ë¦¬ë·° ì½˜í…ì¸ ",
            "â€¢ ì˜¨ë¼ì¸ ê°•ì˜ ë˜ëŠ” ì½”ì¹­ ì„œë¹„ìŠ¤",
            "â€¢ êµ¬ë…ì ì „ìš© ë©¤ë²„ì‹­ í˜œíƒ",
            "â€¢ ê´€ë ¨ ìƒí’ˆ íŒë§¤ (ë¨¸ì²œë‹¤ì´ì¦ˆ)"
        ]
        
        for tip in long_term_tips:
            st.write(tip)

def display_ai_recommendations(visualizer, channel_info):
    """Display AI-powered content recommendations"""
    st.subheader("ğŸ¤– AI ê¸°ë°˜ ì½˜í…ì¸  ì¶”ì²œ")
    
    videos_data = visualizer.videos_data
    if not videos_data:
        st.warning("AI ì¶”ì²œì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # Analyze successful patterns
    top_videos = sorted(videos_data, key=lambda x: x.get('view_count', 0), reverse=True)[:10]
    
    # AI-style recommendations based on data analysis
    st.subheader("ğŸ¯ ë§ì¶¤í˜• ì½˜í…ì¸  ì „ëµ")
    
    # Content type recommendation
    shorts_performance = [v for v in top_videos if v.get('is_short', False)]
    longform_performance = [v for v in top_videos if not v.get('is_short', False)]
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“± ìµœì  ì½˜í…ì¸  í˜•ì‹")
        if len(shorts_performance) > len(longform_performance):
            st.success("ğŸ¯ **ì‡¼ì¸  ì½˜í…ì¸  ì§‘ì¤‘ ì¶”ì²œ**")
            st.write("â€¢ 60ì´ˆ ì´í•˜ ì„íŒ©íŠ¸ ìˆëŠ” ì½˜í…ì¸ ")
            st.write("â€¢ íŠ¸ë Œë”© ìŒì•…ê³¼ í•´ì‹œíƒœê·¸ í™œìš©")
            st.write("â€¢ ë¹ ë¥¸ í¸ì§‘ê³¼ ì‹œê°ì  íš¨ê³¼")
        else:
            st.success("ğŸ¯ **ë¡±í¼ ì½˜í…ì¸  ì§‘ì¤‘ ì¶”ì²œ**")
            st.write("â€¢ 10-15ë¶„ ì‹¬ì¸µ ë¶„ì„ ì½˜í…ì¸ ")
            st.write("â€¢ ìƒì„¸í•œ ì •ë³´ì™€ ìŠ¤í† ë¦¬í…”ë§")
            st.write("â€¢ ì‹œë¦¬ì¦ˆë¬¼ë¡œ êµ¬ë…ì ìœ ì§€")
    
    with col2:
        st.markdown("### â° ìµœì  ì—…ë¡œë“œ ì‹œê°„")
        
        # Find best upload times
        hour_performance = {}
        day_performance = {}
        
        for video in top_videos:
            hour = video['published_at'].hour
            day = video['published_at'].strftime('%A')
            
            if hour not in hour_performance:
                hour_performance[hour] = []
            if day not in day_performance:
                day_performance[day] = []
                
            hour_performance[hour].append(video.get('view_count', 0))
            day_performance[day].append(video.get('view_count', 0))
        
        # Calculate average performance
        best_hour = max(hour_performance.keys(), 
                       key=lambda x: sum(hour_performance[x]) / len(hour_performance[x])) if hour_performance else 12
        best_day = max(day_performance.keys(), 
                      key=lambda x: sum(day_performance[x]) / len(day_performance[x])) if day_performance else "Sunday"
        
        day_names = {
            'Monday': 'ì›”ìš”ì¼', 'Tuesday': 'í™”ìš”ì¼', 'Wednesday': 'ìˆ˜ìš”ì¼',
            'Thursday': 'ëª©ìš”ì¼', 'Friday': 'ê¸ˆìš”ì¼', 'Saturday': 'í† ìš”ì¼', 'Sunday': 'ì¼ìš”ì¼'
        }
        
        st.info(f"ğŸ• **{best_hour}ì‹œ ì—…ë¡œë“œ ì¶”ì²œ**")
        st.info(f"ğŸ“… **{day_names.get(best_day, best_day)} ì—…ë¡œë“œ ì¶”ì²œ**")
    
    # Title optimization
    st.subheader("ğŸ“ ì œëª© ìµœì í™” AI")
    
    # Analyze successful title patterns
    successful_titles = [v['title'] for v in top_videos if v.get('title')]
    
    if successful_titles:
        # Common words analysis
        from collections import Counter
        import re
        
        all_words = []
        for title in successful_titles:
            words = re.findall(r'\b\w+\b', title.lower())
            all_words.extend(words)
        
        common_words = Counter(all_words).most_common(10)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ì„±ê³µ í‚¤ì›Œë“œ TOP 5:**")
            for word, count in common_words[:5]:
                st.write(f"â€¢ {word} ({count}íšŒ)")
        
        with col2:
            st.write("**ì œëª© íŒ¨í„´ ë¶„ì„:**")
            avg_length = sum(len(title) for title in successful_titles) / len(successful_titles)
            question_count = sum(1 for title in successful_titles if '?' in title)
            exclamation_count = sum(1 for title in successful_titles if '!' in title)
            
            st.write(f"â€¢ ìµœì  ì œëª© ê¸¸ì´: {avg_length:.0f}ì")
            st.write(f"â€¢ ë¬¼ìŒí‘œ ì‚¬ìš©: {question_count}ê°œ ì˜ìƒ")
            st.write(f"â€¢ ëŠë‚Œí‘œ ì‚¬ìš©: {exclamation_count}ê°œ ì˜ìƒ")
    
    # Content gap analysis
    st.subheader("ğŸ” ì½˜í…ì¸  ê°­ ë¶„ì„")
    
    # Analyze upload frequency
    if len(videos_data) >= 5:
        recent_uploads = sorted(videos_data, key=lambda x: x['published_at'], reverse=True)[:5]
        upload_gaps = []
        
        for i in range(1, len(recent_uploads)):
            gap = (recent_uploads[i-1]['published_at'] - recent_uploads[i]['published_at']).days
            upload_gaps.append(gap)
        
        avg_gap = sum(upload_gaps) / len(upload_gaps) if upload_gaps else 7
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if avg_gap > 14:
                st.warning("âš ï¸ ì—…ë¡œë“œ ì£¼ê¸°ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤")
                st.write("ê¶Œì¥: ì£¼ 1-2íšŒ ì—…ë¡œë“œ")
            elif avg_gap < 2:
                st.warning("âš ï¸ ë„ˆë¬´ ìì£¼ ì—…ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤")
                st.write("ê¶Œì¥: í’ˆì§ˆ ê´€ë¦¬ì— ì§‘ì¤‘")
            else:
                st.success("âœ… ì ì ˆí•œ ì—…ë¡œë“œ ì£¼ê¸°")
        
        with col2:
            # Suggest trending topics (mock data for demo)
            st.write("**íŠ¸ë Œë”© í† í”½ ì¶”ì²œ:**")
            trending_topics = ["AI í™œìš©ë²•", "2025 íŠ¸ë Œë“œ", "íš¨ìœ¨ì ì¸ ì‘ì—…", "ìƒˆë¡œìš´ ê¸°ìˆ ", "ë¼ì´í”„ìŠ¤íƒ€ì¼"]
            for topic in trending_topics[:3]:
                st.write(f"â€¢ {topic}")
        
        with col3:
            st.write("**ê²½ìŸì ë¶„ì„ í•„ìš”:**")
            st.write("â€¢ ìœ ì‚¬ ì±„ë„ ë²¤ì¹˜ë§ˆí‚¹")
            st.write("â€¢ ì°¨ë³„í™” í¬ì¸íŠ¸ ë°œêµ´")
            st.write("â€¢ í˜‘ì—… ê¸°íšŒ íƒìƒ‰")
    
    # Action plan
    st.subheader("ğŸ“‹ ì‹¤í–‰ ê³„íš")
    
    st.markdown("""
    ### ğŸ¯ ë‹¤ìŒ 30ì¼ ì•¡ì…˜ í”Œëœ
    
    **1ì£¼ì°¨**: ì½˜í…ì¸  ê¸°íš ë° ì œì‘
    - [ ] ì„±ê³µ í‚¤ì›Œë“œ ê¸°ë°˜ ìƒˆ ì½˜í…ì¸  ê¸°íš
    - [ ] ìµœì  ì‹œê°„ëŒ€ ì—…ë¡œë“œ ìŠ¤ì¼€ì¤„ ì„¤ì •
    - [ ] ì¸ë„¤ì¼ A/B í…ŒìŠ¤íŠ¸ ì¤€ë¹„
    
    **2ì£¼ì°¨**: ìµœì í™” ë° ë¶„ì„
    - [ ] ì œëª© íŒ¨í„´ ì ìš© ë° í…ŒìŠ¤íŠ¸
    - [ ] ì‹œì²­ì ì°¸ì—¬ë„ ëª¨ë‹ˆí„°ë§
    - [ ] ëŒ“ê¸€ ë° ì»¤ë®¤ë‹ˆí‹° ê´€ë¦¬ ê°•í™”
    
    **3ì£¼ì°¨**: í™•ì¥ ë° ì‹¤í—˜
    - [ ] ìƒˆë¡œìš´ ì½˜í…ì¸  í˜•ì‹ ì‹¤í—˜
    - [ ] í˜‘ì—… ë˜ëŠ” ê²ŒìŠ¤íŠ¸ ì¶œì—° ê²€í† 
    - [ ] ì‹œë¦¬ì¦ˆ ì½˜í…ì¸  ê¸°íš
    
    **4ì£¼ì°¨**: ë¶„ì„ ë° ê°œì„ 
    - [ ] ì›”ê°„ ì„±ê³¼ ë¶„ì„
    - [ ] ë‹¤ìŒ ë‹¬ ì „ëµ ìˆ˜ì •
    - [ ] ìˆ˜ìµí™” ë°©ì•ˆ ê²€í† 
    """)
    
    # Interactive recommendations
    st.subheader("ğŸ”® ê°œì¸í™”ëœ ì¶”ì²œ")
    
    recommendation_type = st.selectbox(
        "ì–´ë–¤ ë¶„ì•¼ì˜ ì¶”ì²œì„ ë°›ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
        ["ì½˜í…ì¸  ì£¼ì œ", "í¸ì§‘ ìŠ¤íƒ€ì¼", "ë§ˆì¼€íŒ… ì „ëµ", "ìˆ˜ìµí™” ë°©ë²•"]
    )
    
    if recommendation_type == "ì½˜í…ì¸  ì£¼ì œ":
        st.success("ğŸ¬ ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ ì£¼ì œ:")
        st.write("â€¢ ì‹œì²­ìë“¤ì´ ê°€ì¥ ì¢‹ì•„í•˜ëŠ” ìŠ¤íƒ€ì¼ì˜ ì‹¬í™” ë²„ì „")
        st.write("â€¢ í˜„ì¬ íŠ¸ë Œë”© ì¤‘ì¸ í‚¤ì›Œë“œì™€ ì±„ë„ íŠ¹ì„± ê²°í•©")
        st.write("â€¢ ê³„ì ˆì„±ì„ ê³ ë ¤í•œ íƒ€ì´ë° ì½˜í…ì¸ ")
    
    elif recommendation_type == "í¸ì§‘ ìŠ¤íƒ€ì¼":
        st.success("âœ‚ï¸ í¸ì§‘ ìŠ¤íƒ€ì¼ ê°œì„ ì :")
        # Get performance data for editing recommendations
        top_videos = sorted(videos_data, key=lambda x: x.get('view_count', 0), reverse=True)[:10]
        shorts_performance = [v for v in top_videos if v.get('is_short', False)]
        longform_performance = [v for v in top_videos if not v.get('is_short', False)]
        
        if len(shorts_performance) > len(longform_performance):
            st.write("â€¢ ë¹ ë¥¸ ì»· í¸ì§‘ê³¼ ì—­ë™ì ì¸ íŠ¸ëœì§€ì…˜")
            st.write("â€¢ ì‹œê°ì  ì„íŒ©íŠ¸ë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´")
        else:
            st.write("â€¢ ìŠ¤í† ë¦¬í…”ë§ì„ ìœ„í•œ ìì—°ìŠ¤ëŸ¬ìš´ í¸ì§‘")
            st.write("â€¢ ì •ë³´ ì „ë‹¬ì„ ìœ„í•œ ê·¸ë˜í”½ ìš”ì†Œ í™œìš©")
    
    elif recommendation_type == "ë§ˆì¼€íŒ… ì „ëµ":
        st.success("ğŸ“¢ ë§ˆì¼€íŒ… ì „ëµ:")
        st.write("â€¢ ì„±ê³µ ì˜ìƒì˜ í‚¤ì›Œë“œë¥¼ í™œìš©í•œ SEO ìµœì í™”")
        st.write("â€¢ ì‹œì²­ìì™€ì˜ ìƒí˜¸ì‘ìš© ì¦ëŒ€ ë°©ì•ˆ")
        st.write("â€¢ ì†Œì…œë¯¸ë””ì–´ í¬ë¡œìŠ¤ í”„ë¡œëª¨ì…˜")
    
    else:  # ìˆ˜ìµí™” ë°©ë²•
        st.success("ğŸ’° ìˆ˜ìµí™” ì „ëµ:")
        subscriber_count = channel_info.get('subscriber_count', 0)
        if subscriber_count < 1000:
            st.write("â€¢ êµ¬ë…ì 1000ëª… ë‹¬ì„±ì„ ìœ„í•œ ì½˜í…ì¸  ì§‘ì¤‘")
        else:
            st.write("â€¢ ë‹¤ì–‘í•œ ìˆ˜ìµì› ê°œë°œ (ìŠ¤í°ì„œì‹­, ë©¤ë²„ì‹­)")
        st.write("â€¢ ë¸Œëœë“œ ê°€ì¹˜ êµ¬ì¶•ì„ ìœ„í•œ ì¼ê´€ì„± ìˆëŠ” ì½˜í…ì¸ ")

def display_keywords_analysis(visualizer):
    """Display keyword and content analysis"""
    st.subheader("ğŸ”¤ Keywords & Content Analysis")
    
    # Keyword analysis options
    analysis_source = st.selectbox(
        "í‚¤ì›Œë“œ ë¶„ì„ ëŒ€ìƒ:",
        ["titles", "descriptions", "tags"],
        format_func=lambda x: {
            "titles": "ğŸ“ ì˜ìƒ ì œëª©",
            "descriptions": "ğŸ“„ ì„¤ëª…ë€",
            "tags": "ğŸ·ï¸ íƒœê·¸"
        }[x]
    )
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader(f"â˜ï¸ ì›Œë“œ í´ë¼ìš°ë“œ - { {'titles':'ì œëª©','descriptions':'ì„¤ëª…','tags':'íƒœê·¸'}[analysis_source] }")
        wordcloud_fig = visualizer.create_wordcloud(source=analysis_source)
        if wordcloud_fig:
            st.pyplot(wordcloud_fig, use_container_width=True)
        else:
            st.info(f"{ {'titles':'ì œëª©','descriptions':'ì„¤ëª…','tags':'íƒœê·¸'}[analysis_source] } ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with col2:
        st.subheader(f"ğŸ“Š ì£¼ìš” í‚¤ì›Œë“œ - { {'titles':'ì œëª©','descriptions':'ì„¤ëª…','tags':'íƒœê·¸'}[analysis_source] }")
        keywords_fig = visualizer.create_keywords_chart(source=analysis_source, top_n=20)
        if keywords_fig:
            st.plotly_chart(keywords_fig, use_container_width=True)
        else:
            st.info(f"{ {'titles':'ì œëª©','descriptions':'ì„¤ëª…','tags':'íƒœê·¸'}[analysis_source] } ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ í‚¤ì›Œë“œ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


    # ì„±ê³µ ì˜ìƒ íŒ¨í„´
    st.subheader("ğŸ¯ ì„±ê³µ ì˜ìƒ íŒ¨í„´")
    patterns = visualizer.analyze_successful_patterns()

    if patterns:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ”¥ ê³ ì„±ê³¼ í‚¤ì›Œë“œ")
            if patterns.get('top_keywords'):
                for keyword, data in patterns['top_keywords'].items():
                    st.write(f"**{keyword}**: {data['count']}ê°œ ì˜ìƒ, í‰ê·  {data['avg_views']:,.0f}íšŒ ì¡°íšŒìˆ˜")
        
        with col2:
            st.subheader("ğŸ“ˆ ìµœì  ì—…ë¡œë“œ ì‹œê°„")
            if patterns.get('best_times'):
                for time_info in patterns['best_times']:
                    st.write(f"**{time_info['period']}**: í‰ê·  {time_info['avg_views']:,.0f}íšŒ ({time_info['count']}ê°œ ì˜ìƒ)")

def display_detailed_data():
    """Display detailed video data with filtering and sorting"""
    st.subheader("ğŸ“Š ìƒì„¸ ì˜ìƒ ë°ì´í„°")
    
    videos_data = st.session_state.channel_data['videos']
    df = pd.DataFrame(videos_data)
    
    # Filters
    col1, col2, col3 = st.columns(3)
    
    with col1:
        video_type_filter = st.selectbox(
            "ì˜ìƒ ìœ í˜•",
            ["ì „ì²´", "ì‡¼ì¸ ", "ë¡±í¼"],
            key="type_filter"
        )
    
    with col2:
        min_views = st.number_input(
            "ìµœì†Œ ì¡°íšŒìˆ˜",
            min_value=0,
            value=0,
            key="min_views_filter"
        )
    
    with col3:
        date_range = st.date_input(
            "ë‚ ì§œ ë²”ìœ„",
            value=[],
            key="date_filter"
        )
    
    # Apply filters
    filtered_df = df.copy()
    
    if video_type_filter != "All":
        is_short = video_type_filter == "Shorts"
        filtered_df = filtered_df[filtered_df['is_short'] == is_short]
    
    if min_views > 0:
        filtered_df = filtered_df[filtered_df['view_count'] >= min_views]
    
    # Search functionality
    search_term = st.text_input("ğŸ” ì œëª© ë‚´ ê²€ìƒ‰", key="search_filter")
    if search_term:
        filtered_df = filtered_df[filtered_df['title'].str.contains(search_term, case=False, na=False)]
    
    # Display filtered data
    st.write(f"Showing {len(filtered_df)} of {len(df)} videos")
    
    # Select columns to display
    available_columns = ['title', 'published_at', 'view_count', 'like_count', 'comment_count', 
                        'duration_formatted', 'is_short', 'tags']
    selected_columns = st.multiselect(
        "í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ",
        available_columns,
        default=['title', 'published_at', 'view_count', 'like_count', 'comment_count', 'duration_formatted'],
        key="column_selector"
    )
    
    if selected_columns:
        display_df = filtered_df[selected_columns].copy()
        
        # Format column names
        column_mapping = {
            'title': 'ì œëª©',
            'published_at': 'ì—…ë¡œë“œì¼',
            'view_count': 'ì¡°íšŒìˆ˜',
            'like_count': 'ì¢‹ì•„ìš”',
            'comment_count': 'ëŒ“ê¸€ìˆ˜',
            'duration_formatted': 'ê¸¸ì´',
            'is_short': 'ìœ í˜•',
            'tags': 'íƒœê·¸'
        }
        
        display_df = display_df.rename(columns=column_mapping)
        
        if 'Type' in display_df.columns:
            display_df['Type'] = display_df['Type'].map({True: 'Shorts', False: 'Long-form'})
        
        st.dataframe(
            display_df,
            use_container_width=True,
            hide_index=True
        )

def display_export_options(visualizer):
    """Display export and reporting options"""
    st.subheader("ğŸ“‹ ë‚´ë³´ë‚´ê¸° ë° ë¦¬í¬íŠ¸")
    
    videos_data = st.session_state.channel_data['videos']
    channel_info = st.session_state.channel_data['channel_info']
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š ë°ì´í„° ë‚´ë³´ë‚´ê¸°")
        
        # CSV export
        if st.button("ğŸ“„ CSVë¡œ ë‚´ë³´ë‚´ê¸°", use_container_width=True):
            df = pd.DataFrame(videos_data)
            csv = df.to_csv(index=False)
            st.download_button(
                label="ğŸ’¾ Download CSV",
                data=csv,
                file_name=f"{channel_info.get('title', 'channel')}_analysis.csv",
                mime='text/csv',
                use_container_width=True
            )
        
        # JSON export
        if st.button("ğŸ“‹ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°", use_container_width=True):
            import json
            json_data = json.dumps(st.session_state.channel_data, indent=2, default=str)
            st.download_button(
                label="ğŸ’¾ Download JSON",
                data=json_data,
                file_name=f"{channel_info.get('title', 'channel')}_analysis.json",
                mime='application/json',
                use_container_width=True
            )
    
    with col2:
        st.subheader("ğŸ“ˆ ë¶„ì„ ìš”ì•½")
        
        # Generate summary report
        summary = visualizer.generate_summary_report(channel_info)
        
        st.markdown("### ğŸ“‹ Channel Analysis Summary")
        for key, value in summary.items():
            if isinstance(value, dict):
                st.markdown(f"**{key}:**")
                for sub_key, sub_value in value.items():
                    st.markdown(f"  - {sub_key}: {sub_value}")
            else:
                st.markdown(f"**{key}:** {value}")
        
        # Export summary as text
        summary_text = "\n".join([f"{k}: {v}" for k, v in summary.items()])
        st.download_button(
            label="ğŸ“„ ìš”ì•½ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
            data=summary_text,
            file_name=f"{channel_info.get('title', 'ì±„ë„')}_summary.txt",
            mime='text/plain',
            use_container_width=True
        )

if __name__ == "__main__":
    main()
